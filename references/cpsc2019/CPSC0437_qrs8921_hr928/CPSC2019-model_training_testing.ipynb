{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train CPSC2019 segment_4S dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel_size:  11\n",
      "drop_rate:  0.2\n",
      "filter_num:  16\n",
      "use_lstm:  True\n",
      "varyLR:  True\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "data (InputLayer)               (None, None, 2)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv1D)           (None, None, 16)     368         data[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, None, 16)     64          block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, None, 16)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv1D)           (None, None, 16)     2832        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, None, 16)     64          block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling1D)            (None, None, 16)     0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv1D)           (None, None, 16)     2832        pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, None, 16)     64          block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, None, 16)     0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv1D)           (None, None, 16)     2832        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, None, 16)     64          block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "pool2 (MaxPooling1D)            (None, None, 16)     0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv1D)           (None, None, 32)     5664        pool2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, None, 32)     128         block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, None, 32)     0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv1D)           (None, None, 32)     11296       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, None, 32)     128         block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "pool3 (MaxPooling1D)            (None, None, 32)     0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv1D)           (None, None, 32)     11296       pool3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, None, 32)     128         block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, None, 32)     0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv1D)           (None, None, 32)     11296       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, None, 32)     128         block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "pool4 (MaxPooling1D)            (None, None, 32)     0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv1D)           (None, None, 64)     22592       pool4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, None, 64)     256         block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, None, 64)     0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv1D)           (None, None, 64)     45120       dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, None, 64)     256         block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "pool5 (MaxPooling1D)            (None, None, 64)     0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block6_conv1 (Conv1D)           (None, None, 64)     45120       pool5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, None, 64)     256         block6_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, None, 64)     0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block6_conv2 (Conv1D)           (None, None, 64)     45120       dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, None, 64)     256         block6_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "pool6 (MaxPooling1D)            (None, None, 64)     0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block7_conv1 (Conv1D)           (None, None, 128)    90240       pool6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, None, 128)    512         block7_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, None, 128)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block7_conv2 (Conv1D)           (None, None, 128)    180352      dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, None, 128)    512         block7_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "pool7 (MaxPooling1D)            (None, None, 128)    0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block8_conv1 (Conv1D)           (None, None, 128)    180352      pool7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, None, 128)    512         block8_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, None, 128)    0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block8_conv2 (Conv1D)           (None, None, 128)    180352      dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, None, 128)    512         block8_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "pool8 (MaxPooling1D)            (None, None, 128)    0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block9_conv1 (Conv1D)           (None, None, 256)    360704      pool8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, None, 256)    1024        block9_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, None, 256)    0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block9_conv2 (Conv1D)           (None, None, 256)    721152      dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, None, 256)    1024        block9_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "pool9 (MaxPooling1D)            (None, None, 256)    0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block10_conv1 (Conv1D)          (None, None, 256)    721152      pool9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, None, 256)    1024        block10_conv1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, None, 256)    0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block10_conv2 (Conv1D)          (None, None, 256)    721152      dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, None, 256)    1024        block10_conv2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, None, 256)    394240      batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_1 (UpSampling1D)  (None, None, 256)    0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "up9 (Conv1D)                    (None, None, 256)    65792       up_sampling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, 512)    0           up9[0][0]                        \n",
      "                                                                 batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "deconv9_conv1 (Conv1D)          (None, None, 128)    721024      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, None, 128)    512         deconv9_conv1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, None, 128)    0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "deconv9_conv2 (Conv1D)          (None, None, 128)    180352      dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, None, 128)    512         deconv9_conv2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_2 (UpSampling1D)  (None, None, 128)    0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up8 (Conv1D)                    (None, None, 128)    16512       up_sampling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, None, 256)    0           up8[0][0]                        \n",
      "                                                                 batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "deconv8_conv1 (Conv1D)          (None, None, 128)    360576      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, None, 128)    512         deconv8_conv1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, None, 128)    0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "deconv8_conv2 (Conv1D)          (None, None, 128)    180352      dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, None, 128)    512         deconv8_conv2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_3 (UpSampling1D)  (None, None, 128)    0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up7 (Conv1D)                    (None, None, 128)    16512       up_sampling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, None, 256)    0           up7[0][0]                        \n",
      "                                                                 batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "deconv7_conv1 (Conv1D)          (None, None, 128)    360576      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, None, 128)    512         deconv7_conv1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, None, 128)    0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "deconv7_conv2 (Conv1D)          (None, None, 128)    180352      dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, None, 128)    512         deconv7_conv2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_4 (UpSampling1D)  (None, None, 128)    0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up6 (Conv1D)                    (None, None, 64)     8256        up_sampling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, None, 128)    0           up6[0][0]                        \n",
      "                                                                 batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "deconv6_conv1 (Conv1D)          (None, None, 16)     22544       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, None, 16)     64          deconv6_conv1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, None, 16)     0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "deconv6_conv2 (Conv1D)          (None, None, 16)     2832        dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, None, 16)     64          deconv6_conv2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_5 (UpSampling1D)  (None, None, 16)     0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up5 (Conv1D)                    (None, None, 64)     1088        up_sampling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, None, 128)    0           up5[0][0]                        \n",
      "                                                                 batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "deconv5_conv1 (Conv1D)          (None, None, 16)     22544       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, None, 16)     64          deconv5_conv1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, None, 16)     0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "deconv5_conv2 (Conv1D)          (None, None, 16)     2832        dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, None, 16)     64          deconv5_conv2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_6 (UpSampling1D)  (None, None, 16)     0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up4 (Conv1D)                    (None, None, 32)     544         up_sampling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, None, 64)     0           up4[0][0]                        \n",
      "                                                                 batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "deconv4_conv1 (Conv1D)          (None, None, 16)     11280       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, None, 16)     64          deconv4_conv1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, None, 16)     0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "deconv4_conv2 (Conv1D)          (None, None, 16)     2832        dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, None, 16)     64          deconv4_conv2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_7 (UpSampling1D)  (None, None, 16)     0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up3 (Conv1D)                    (None, None, 32)     544         up_sampling1d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, None, 64)     0           up3[0][0]                        \n",
      "                                                                 batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "deconv3_conv1 (Conv1D)          (None, None, 16)     11280       concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, None, 16)     64          deconv3_conv1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, None, 16)     0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "deconv3_conv2 (Conv1D)          (None, None, 16)     2832        dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, None, 16)     64          deconv3_conv2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_8 (UpSampling1D)  (None, None, 16)     0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up2 (Conv1D)                    (None, None, 16)     272         up_sampling1d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, None, 32)     0           up2[0][0]                        \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "deconv2_conv1 (Conv1D)          (None, None, 16)     5648        concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, None, 16)     64          deconv2_conv1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, None, 16)     0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "deconv2_conv2 (Conv1D)          (None, None, 16)     2832        dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, None, 16)     64          deconv2_conv2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_9 (UpSampling1D)  (None, None, 16)     0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up1 (Conv1D)                    (None, None, 16)     272         up_sampling1d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, None, 32)     0           up1[0][0]                        \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "deconv1_conv1 (Conv1D)          (None, None, 16)     5648        concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, None, 16)     64          deconv1_conv1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, None, 16)     0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "deconv1_conv2 (Conv1D)          (None, None, 16)     2832        dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, None, 16)     64          deconv1_conv2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv10 (Conv1D)                 (None, None, 1)      17          batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Conv1D)            (None, None, 1)      2           conv10[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 5,956,819\n",
      "Trainable params: 5,950,931\n",
      "Non-trainable params: 5,888\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape (2000, 5000, 1)\n",
      "Y.shape (2000, 5000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Roaming\\Python\\Python35\\site-packages\\sklearn\\preprocessing\\data.py:180: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\dell\\AppData\\Roaming\\Python\\Python35\\site-packages\\sklearn\\preprocessing\\data.py:197: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 5000, 2)\n",
      "(2000, 5000, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validating...\n",
      "lr:  0.001\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 92s 8ms/step - loss: 0.0329 - val_loss: 0.0181\n",
      "0.6149999999999995\n",
      "Total score: 0.6149999999999995\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0169 - val_loss: 0.0157\n",
      "0.7007499999999993\n",
      "Total score: 0.7007499999999993\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 64s 6ms/step - loss: 0.0152 - val_loss: 0.0149\n",
      "0.7437499999999996\n",
      "Total score: 0.7437499999999996\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0142 - val_loss: 0.0137\n",
      "0.7742499999999995\n",
      "Total score: 0.7742499999999995\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 64s 6ms/step - loss: 0.0132 - val_loss: 0.0130\n",
      "0.7934999999999998\n",
      "Total score: 0.7934999999999998\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0122 - val_loss: 0.0124\n",
      "0.8082499999999999\n",
      "Total score: 0.8082499999999999\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 64s 6ms/step - loss: 0.0113 - val_loss: 0.0113\n",
      "0.8284999999999999\n",
      "Total score: 0.8284999999999999\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0103 - val_loss: 0.0108\n",
      "0.8534999999999998\n",
      "Total score: 0.8534999999999998\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0094 - val_loss: 0.0097\n",
      "0.8637499999999999\n",
      "Total score: 0.8637499999999999\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0086 - val_loss: 0.0094\n",
      "0.848\n",
      "Total score: 0.848\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0080 - val_loss: 0.0088\n",
      "0.8739999999999998\n",
      "Total score: 0.8739999999999998\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0075 - val_loss: 0.0088\n",
      "0.8739999999999998\n",
      "Total score: 0.8739999999999998\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0071 - val_loss: 0.0089\n",
      "0.884\n",
      "Total score: 0.884\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0068 - val_loss: 0.0087\n",
      "0.8827499999999999\n",
      "Total score: 0.8827499999999999\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 64s 6ms/step - loss: 0.0066 - val_loss: 0.0086\n",
      "0.8969999999999999\n",
      "Total score: 0.8969999999999999\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0064 - val_loss: 0.0084\n",
      "0.89225\n",
      "Total score: 0.89225\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 64s 6ms/step - loss: 0.0062 - val_loss: 0.0084\n",
      "0.9032499999999998\n",
      "Total score: 0.9032499999999998\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0061 - val_loss: 0.0085\n",
      "0.8847499999999999\n",
      "Total score: 0.8847499999999999\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0059 - val_loss: 0.0086\n",
      "0.8989999999999999\n",
      "Total score: 0.8989999999999999\n",
      "current_patience:  2\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0058 - val_loss: 0.0088\n",
      "0.879\n",
      "Total score: 0.879\n",
      "current_patience:  3\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0059 - val_loss: 0.0084\n",
      "0.8972499999999998\n",
      "Total score: 0.8972499999999998\n",
      "current_patience:  4\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 64s 6ms/step - loss: 0.0058 - val_loss: 0.0085\n",
      "0.8912499999999999\n",
      "Total score: 0.8912499999999999\n",
      "current_patience:  5\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0057 - val_loss: 0.0084\n",
      "0.9137499999999998\n",
      "Total score: 0.9137499999999998\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0056 - val_loss: 0.0086\n",
      "0.8992499999999999\n",
      "Total score: 0.8992499999999999\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0055 - val_loss: 0.0086\n",
      "0.8989999999999999\n",
      "Total score: 0.8989999999999999\n",
      "current_patience:  2\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0054 - val_loss: 0.0087\n",
      "0.8949999999999999\n",
      "Total score: 0.8949999999999999\n",
      "current_patience:  3\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.00025\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0055 - val_loss: 0.0085\n",
      "0.9012499999999999\n",
      "Total score: 0.9012499999999999\n",
      "current_patience:  4\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.00025\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0054 - val_loss: 0.0086\n",
      "0.9027499999999999\n",
      "Total score: 0.9027499999999999\n",
      "current_patience:  5\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.00025\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0053 - val_loss: 0.0085\n",
      "0.9047499999999999\n",
      "Total score: 0.9047499999999999\n",
      "current_patience:  6\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.000125\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0055 - val_loss: 0.0085\n",
      "0.9044999999999999\n",
      "Total score: 0.9044999999999999\n",
      "current_patience:  7\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.000125\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0054 - val_loss: 0.0085\n",
      "0.9047499999999998\n",
      "Total score: 0.9047499999999998\n",
      "current_patience:  8\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.000125\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0054 - val_loss: 0.0086\n",
      "0.9059999999999999\n",
      "Total score: 0.9059999999999999\n",
      "current_patience:  9\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  6.25e-05\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0055 - val_loss: 0.0085\n",
      "0.8985\n",
      "Total score: 0.8985\n",
      "current_patience:  10\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  6.25e-05\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0054 - val_loss: 0.0085\n",
      "0.9089999999999999\n",
      "Total score: 0.9089999999999999\n",
      "current_patience:  11\n",
      "0.8869999999999993\n",
      "0.050000: 0.887000\n",
      "0.9044999999999994\n",
      "0.100000: 0.904500\n",
      "0.9087499999999997\n",
      "0.150000: 0.908750\n",
      "0.9092499999999998\n",
      "0.200000: 0.909250\n",
      "0.9137499999999998\n",
      "0.250000: 0.913750\n",
      "0.9117499999999998\n",
      "0.300000: 0.911750\n",
      "0.9102499999999999\n",
      "0.350000: 0.910250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.89825\n",
      "0.400000: 0.898250\n",
      "0.8989999999999999\n",
      "0.450000: 0.899000\n",
      "0.8902500000000001\n",
      "0.500000: 0.890250\n",
      "0.8832500000000002\n",
      "0.550000: 0.883250\n",
      "0.8717500000000004\n",
      "0.600000: 0.871750\n",
      "0.8407500000000004\n",
      "0.650000: 0.840750\n",
      "0.8035000000000007\n",
      "0.700000: 0.803500\n",
      "0.7312500000000013\n",
      "0.750000: 0.731250\n",
      "0.6417500000000012\n",
      "0.800000: 0.641750\n",
      "0.0\n",
      "0.850000: 0.000000\n",
      "0.0\n",
      "0.900000: 0.000000\n",
      "0.0\n",
      "0.950000: 0.000000\n",
      "lr:  0.001\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0358 - val_loss: 0.0185\n",
      "0.6054999999999995\n",
      "Total score: 0.6054999999999995\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 64s 6ms/step - loss: 0.0169 - val_loss: 0.0164\n",
      "0.6737499999999993\n",
      "Total score: 0.6737499999999993\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 64s 6ms/step - loss: 0.0150 - val_loss: 0.0152\n",
      "0.7342499999999993\n",
      "Total score: 0.7342499999999993\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 64s 6ms/step - loss: 0.0139 - val_loss: 0.0144\n",
      "0.7614999999999996\n",
      "Total score: 0.7614999999999996\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0129 - val_loss: 0.0133\n",
      "0.7927499999999994\n",
      "Total score: 0.7927499999999994\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 64s 6ms/step - loss: 0.0120 - val_loss: 0.0126\n",
      "0.8137499999999999\n",
      "Total score: 0.8137499999999999\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0111 - val_loss: 0.0117\n",
      "0.8369999999999996\n",
      "Total score: 0.8369999999999996\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0101 - val_loss: 0.0111\n",
      "0.8397499999999997\n",
      "Total score: 0.8397499999999997\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0093 - val_loss: 0.0106\n",
      "0.8479999999999996\n",
      "Total score: 0.8479999999999996\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0085 - val_loss: 0.0099\n",
      "0.8645\n",
      "Total score: 0.8645\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0079 - val_loss: 0.0097\n",
      "0.8654999999999999\n",
      "Total score: 0.8654999999999999\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0074 - val_loss: 0.0091\n",
      "0.8935000000000001\n",
      "Total score: 0.8935000000000001\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0071 - val_loss: 0.0087\n",
      "0.89325\n",
      "Total score: 0.89325\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0068 - val_loss: 0.0088\n",
      "0.8827499999999999\n",
      "Total score: 0.8827499999999999\n",
      "current_patience:  2\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0065 - val_loss: 0.0089\n",
      "0.888\n",
      "Total score: 0.888\n",
      "current_patience:  3\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0069 - val_loss: 0.0090\n",
      "0.9047499999999999\n",
      "Total score: 0.9047499999999999\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0067 - val_loss: 0.0089\n",
      "0.9005000000000001\n",
      "Total score: 0.9005000000000001\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0065 - val_loss: 0.0089\n",
      "0.8924999999999998\n",
      "Total score: 0.8924999999999998\n",
      "current_patience:  2\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0063 - val_loss: 0.0086\n",
      "0.898\n",
      "Total score: 0.898\n",
      "current_patience:  3\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.00025\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0066 - val_loss: 0.0089\n",
      "0.9045000000000001\n",
      "Total score: 0.9045000000000001\n",
      "current_patience:  4\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.00025\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0065 - val_loss: 0.0089\n",
      "0.9005\n",
      "Total score: 0.9005\n",
      "current_patience:  5\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.00025\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0064 - val_loss: 0.0088\n",
      "0.89825\n",
      "Total score: 0.89825\n",
      "current_patience:  6\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.000125\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0066 - val_loss: 0.0089\n",
      "0.8902500000000001\n",
      "Total score: 0.8902500000000001\n",
      "current_patience:  7\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.000125\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0065 - val_loss: 0.0089\n",
      "0.8909999999999999\n",
      "Total score: 0.8909999999999999\n",
      "current_patience:  8\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.000125\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0064 - val_loss: 0.0089\n",
      "0.8942500000000001\n",
      "Total score: 0.8942500000000001\n",
      "current_patience:  9\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  6.25e-05\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0066 - val_loss: 0.0089\n",
      "0.90475\n",
      "Total score: 0.90475\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  6.25e-05\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0066 - val_loss: 0.0088\n",
      "0.9002499999999999\n",
      "Total score: 0.9002499999999999\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  6.25e-05\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0066 - val_loss: 0.0089\n",
      "0.8925\n",
      "Total score: 0.8925\n",
      "current_patience:  2\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  6.25e-05\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0065 - val_loss: 0.0089\n",
      "0.89375\n",
      "Total score: 0.89375\n",
      "current_patience:  3\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  3.125e-05\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0066 - val_loss: 0.0088\n",
      "0.90275\n",
      "Total score: 0.90275\n",
      "current_patience:  4\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  3.125e-05\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0065 - val_loss: 0.0089\n",
      "0.90275\n",
      "Total score: 0.90275\n",
      "current_patience:  5\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  3.125e-05\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0065 - val_loss: 0.0089\n",
      "0.90275\n",
      "Total score: 0.90275\n",
      "current_patience:  6\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  1.5625e-05\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0066 - val_loss: 0.0089\n",
      "0.9079999999999999\n",
      "Total score: 0.9079999999999999\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  1.5625e-05\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0066 - val_loss: 0.0089\n",
      "0.8965\n",
      "Total score: 0.8965\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  1.5625e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0065 - val_loss: 0.0088\n",
      "0.90125\n",
      "Total score: 0.90125\n",
      "current_patience:  2\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  1.5625e-05\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0065 - val_loss: 0.0089\n",
      "0.90225\n",
      "Total score: 0.90225\n",
      "current_patience:  3\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  7.8125e-06\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0066 - val_loss: 0.0089\n",
      "0.9079999999999999\n",
      "Total score: 0.9079999999999999\n",
      "current_patience:  4\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  7.8125e-06\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0066 - val_loss: 0.0089\n",
      "0.90625\n",
      "Total score: 0.90625\n",
      "current_patience:  5\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  7.8125e-06\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0066 - val_loss: 0.0089\n",
      "0.903\n",
      "Total score: 0.903\n",
      "current_patience:  6\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  3.90625e-06\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0066 - val_loss: 0.0089\n",
      "0.9055\n",
      "Total score: 0.9055\n",
      "current_patience:  7\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  3.90625e-06\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0066 - val_loss: 0.0089\n",
      "0.90375\n",
      "Total score: 0.90375\n",
      "current_patience:  8\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  3.90625e-06\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0065 - val_loss: 0.0089\n",
      "0.9005\n",
      "Total score: 0.9005\n",
      "current_patience:  9\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  1.953125e-06\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0066 - val_loss: 0.0089\n",
      "0.9055\n",
      "Total score: 0.9055\n",
      "current_patience:  10\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  1.953125e-06\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0065 - val_loss: 0.0089\n",
      "0.903\n",
      "Total score: 0.903\n",
      "current_patience:  11\n",
      "0.8799999999999996\n",
      "0.050000: 0.880000\n",
      "0.8957499999999997\n",
      "0.100000: 0.895750\n",
      "0.9059999999999999\n",
      "0.150000: 0.906000\n",
      "0.9082499999999999\n",
      "0.200000: 0.908250\n",
      "0.9079999999999999\n",
      "0.250000: 0.908000\n",
      "0.9050000000000001\n",
      "0.300000: 0.905000\n",
      "0.9015000000000001\n",
      "0.350000: 0.901500\n",
      "0.8917500000000002\n",
      "0.400000: 0.891750\n",
      "0.8882500000000002\n",
      "0.450000: 0.888250\n",
      "0.8862500000000003\n",
      "0.500000: 0.886250\n",
      "0.8775000000000003\n",
      "0.550000: 0.877500\n",
      "0.8580000000000002\n",
      "0.600000: 0.858000\n",
      "0.8297500000000003\n",
      "0.650000: 0.829750\n",
      "0.7792500000000007\n",
      "0.700000: 0.779250\n",
      "0.7230000000000009\n",
      "0.750000: 0.723000\n",
      "0.0\n",
      "0.800000: 0.000000\n",
      "0.0\n",
      "0.850000: 0.000000\n",
      "0.0\n",
      "0.900000: 0.000000\n",
      "0.0\n",
      "0.950000: 0.000000\n",
      "lr:  0.001\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 61s 5ms/step - loss: 0.0360 - val_loss: 0.0180\n",
      "0.6379999999999996\n",
      "Total score: 0.6379999999999996\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0172 - val_loss: 0.0157\n",
      "0.7212499999999998\n",
      "Total score: 0.7212499999999998\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0153 - val_loss: 0.0147\n",
      "0.7552499999999995\n",
      "Total score: 0.7552499999999995\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0142 - val_loss: 0.0138\n",
      "0.7984999999999997\n",
      "Total score: 0.7984999999999997\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0132 - val_loss: 0.0128\n",
      "0.8192499999999996\n",
      "Total score: 0.8192499999999996\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0123 - val_loss: 0.0118\n",
      "0.8572499999999998\n",
      "Total score: 0.8572499999999998\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0115 - val_loss: 0.0114\n",
      "0.8522499999999996\n",
      "Total score: 0.8522499999999996\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0105 - val_loss: 0.0108\n",
      "0.8574999999999998\n",
      "Total score: 0.8574999999999998\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0096 - val_loss: 0.0097\n",
      "0.882\n",
      "Total score: 0.882\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0087 - val_loss: 0.0092\n",
      "0.8630000000000001\n",
      "Total score: 0.8630000000000001\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0081 - val_loss: 0.0087\n",
      "0.8560000000000002\n",
      "Total score: 0.8560000000000002\n",
      "current_patience:  2\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0076 - val_loss: 0.0082\n",
      "0.8625000000000002\n",
      "Total score: 0.8625000000000002\n",
      "current_patience:  3\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0087 - val_loss: 0.0094\n",
      "0.8800000000000001\n",
      "Total score: 0.8800000000000001\n",
      "current_patience:  4\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0083 - val_loss: 0.0087\n",
      "0.884\n",
      "Total score: 0.884\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0079 - val_loss: 0.0086\n",
      "0.88425\n",
      "Total score: 0.88425\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0076 - val_loss: 0.0084\n",
      "0.885\n",
      "Total score: 0.885\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0073 - val_loss: 0.0081\n",
      "0.88575\n",
      "Total score: 0.88575\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "0.8969999999999999\n",
      "Total score: 0.8969999999999999\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0069 - val_loss: 0.0082\n",
      "0.88075\n",
      "Total score: 0.88075\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0068 - val_loss: 0.0085\n",
      "0.87575\n",
      "Total score: 0.87575\n",
      "current_patience:  2\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0066 - val_loss: 0.0079\n",
      "0.89325\n",
      "Total score: 0.89325\n",
      "current_patience:  3\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.00025\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0069 - val_loss: 0.0081\n",
      "0.8989999999999999\n",
      "Total score: 0.8989999999999999\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.00025\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0067 - val_loss: 0.0084\n",
      "0.8882499999999999\n",
      "Total score: 0.8882499999999999\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.00025\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0066 - val_loss: 0.0080\n",
      "0.8909999999999999\n",
      "Total score: 0.8909999999999999\n",
      "current_patience:  2\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.00025\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0065 - val_loss: 0.0080\n",
      "0.8937499999999998\n",
      "Total score: 0.8937499999999998\n",
      "current_patience:  3\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.000125\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0067 - val_loss: 0.0080\n",
      "0.9002499999999999\n",
      "Total score: 0.9002499999999999\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.000125\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0066 - val_loss: 0.0081\n",
      "0.9042499999999998\n",
      "Total score: 0.9042499999999998\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.000125\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0066 - val_loss: 0.0081\n",
      "0.89725\n",
      "Total score: 0.89725\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.000125\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0065 - val_loss: 0.0080\n",
      "0.90575\n",
      "Total score: 0.90575\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.000125\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0065 - val_loss: 0.0081\n",
      "0.9032499999999999\n",
      "Total score: 0.9032499999999999\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.000125\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0064 - val_loss: 0.0081\n",
      "0.8957499999999999\n",
      "Total score: 0.8957499999999999\n",
      "current_patience:  2\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.000125\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0063 - val_loss: 0.0079\n",
      "0.90225\n",
      "Total score: 0.90225\n",
      "current_patience:  3\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  6.25e-05\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0065 - val_loss: 0.0080\n",
      "0.90325\n",
      "Total score: 0.90325\n",
      "current_patience:  4\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  6.25e-05\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0064 - val_loss: 0.0080\n",
      "0.90475\n",
      "Total score: 0.90475\n",
      "current_patience:  5\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  6.25e-05\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0064 - val_loss: 0.0081\n",
      "0.909\n",
      "Total score: 0.909\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  6.25e-05\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0063 - val_loss: 0.0080\n",
      "0.9075\n",
      "Total score: 0.9075\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  6.25e-05\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0063 - val_loss: 0.0079\n",
      "0.9012500000000001\n",
      "Total score: 0.9012500000000001\n",
      "current_patience:  2\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  6.25e-05\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0063 - val_loss: 0.0081\n",
      "0.9015000000000001\n",
      "Total score: 0.9015000000000001\n",
      "current_patience:  3\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  3.125e-05\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0064 - val_loss: 0.0080\n",
      "0.9064999999999999\n",
      "Total score: 0.9064999999999999\n",
      "current_patience:  4\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  3.125e-05\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0063 - val_loss: 0.0080\n",
      "0.9039999999999999\n",
      "Total score: 0.9039999999999999\n",
      "current_patience:  5\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  3.125e-05\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0063 - val_loss: 0.0079\n",
      "0.9064999999999999\n",
      "Total score: 0.9064999999999999\n",
      "current_patience:  6\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  1.5625e-05\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0064 - val_loss: 0.0081\n",
      "0.9039999999999999\n",
      "Total score: 0.9039999999999999\n",
      "current_patience:  7\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  1.5625e-05\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0063 - val_loss: 0.0080\n",
      "0.9047499999999999\n",
      "Total score: 0.9047499999999999\n",
      "current_patience:  8\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  1.5625e-05\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0063 - val_loss: 0.0080\n",
      "0.90225\n",
      "Total score: 0.90225\n",
      "current_patience:  9\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  7.8125e-06\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0064 - val_loss: 0.0080\n",
      "0.9065000000000001\n",
      "Total score: 0.9065000000000001\n",
      "current_patience:  10\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  7.8125e-06\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0063 - val_loss: 0.0081\n",
      "0.90575\n",
      "Total score: 0.90575\n",
      "current_patience:  11\n",
      "0.8917499999999996\n",
      "0.050000: 0.891750\n",
      "0.9015\n",
      "0.100000: 0.901500\n",
      "0.9029999999999998\n",
      "0.150000: 0.903000\n",
      "0.90775\n",
      "0.200000: 0.907750\n",
      "0.909\n",
      "0.250000: 0.909000\n",
      "0.9010000000000001\n",
      "0.300000: 0.901000\n",
      "0.8992500000000001\n",
      "0.350000: 0.899250\n",
      "0.8967500000000002\n",
      "0.400000: 0.896750\n",
      "0.8907500000000002\n",
      "0.450000: 0.890750\n",
      "0.8820000000000003\n",
      "0.500000: 0.882000\n",
      "0.8700000000000003\n",
      "0.550000: 0.870000\n",
      "0.8517500000000006\n",
      "0.600000: 0.851750\n",
      "0.8182500000000007\n",
      "0.650000: 0.818250\n",
      "0.7805000000000006\n",
      "0.700000: 0.780500\n",
      "0.6967500000000009\n",
      "0.750000: 0.696750\n",
      "0.0\n",
      "0.800000: 0.000000\n",
      "0.0\n",
      "0.850000: 0.000000\n",
      "0.0\n",
      "0.900000: 0.000000\n",
      "0.0\n",
      "0.950000: 0.000000\n",
      "lr:  0.001\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 62s 5ms/step - loss: 0.0361 - val_loss: 0.0173\n",
      "0.6309999999999996\n",
      "Total score: 0.6309999999999996\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0173 - val_loss: 0.0155\n",
      "0.6892499999999996\n",
      "Total score: 0.6892499999999996\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0154 - val_loss: 0.0139\n",
      "0.7479999999999994\n",
      "Total score: 0.7479999999999994\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0143 - val_loss: 0.0133\n",
      "0.7454999999999994\n",
      "Total score: 0.7454999999999994\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0133 - val_loss: 0.0123\n",
      "0.7954999999999994\n",
      "Total score: 0.7954999999999994\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0124 - val_loss: 0.0117\n",
      "0.8209999999999995\n",
      "Total score: 0.8209999999999995\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0114 - val_loss: 0.0108\n",
      "0.8324999999999995\n",
      "Total score: 0.8324999999999995\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0105 - val_loss: 0.0100\n",
      "0.8432499999999997\n",
      "Total score: 0.8432499999999997\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0096 - val_loss: 0.0093\n",
      "0.8512499999999996\n",
      "Total score: 0.8512499999999996\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0089 - val_loss: 0.0087\n",
      "0.8614999999999998\n",
      "Total score: 0.8614999999999998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0082 - val_loss: 0.0080\n",
      "0.8709999999999998\n",
      "Total score: 0.8709999999999998\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0077 - val_loss: 0.0078\n",
      "0.8640000000000001\n",
      "Total score: 0.8640000000000001\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0074 - val_loss: 0.0077\n",
      "0.8727499999999999\n",
      "Total score: 0.8727499999999999\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0071 - val_loss: 0.0078\n",
      "0.8827499999999998\n",
      "Total score: 0.8827499999999998\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0069 - val_loss: 0.0076\n",
      "0.8747499999999999\n",
      "Total score: 0.8747499999999999\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0067 - val_loss: 0.0073\n",
      "0.8967499999999999\n",
      "Total score: 0.8967499999999999\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0065 - val_loss: 0.0078\n",
      "0.8922499999999998\n",
      "Total score: 0.8922499999999998\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0063 - val_loss: 0.0076\n",
      "0.8924999999999997\n",
      "Total score: 0.8924999999999997\n",
      "current_patience:  2\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0061 - val_loss: 0.0077\n",
      "0.9009999999999998\n",
      "Total score: 0.9009999999999998\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0060 - val_loss: 0.0075\n",
      "0.9057499999999998\n",
      "Total score: 0.9057499999999998\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0058 - val_loss: 0.0075\n",
      "0.8949999999999997\n",
      "Total score: 0.8949999999999997\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0057 - val_loss: 0.0082\n",
      "0.8992499999999999\n",
      "Total score: 0.8992499999999999\n",
      "current_patience:  2\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0056 - val_loss: 0.0077\n",
      "0.8932499999999999\n",
      "Total score: 0.8932499999999999\n",
      "current_patience:  3\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0057 - val_loss: 0.0074\n",
      "0.90425\n",
      "Total score: 0.90425\n",
      "current_patience:  4\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0055 - val_loss: 0.0075\n",
      "0.9162499999999999\n",
      "Total score: 0.9162499999999999\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0054 - val_loss: 0.0080\n",
      "0.9112499999999999\n",
      "Total score: 0.9112499999999999\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0053 - val_loss: 0.0076\n",
      "0.903\n",
      "Total score: 0.903\n",
      "current_patience:  2\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0052 - val_loss: 0.0075\n",
      "0.9182499999999999\n",
      "Total score: 0.9182499999999999\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0051 - val_loss: 0.0077\n",
      "0.9057499999999998\n",
      "Total score: 0.9057499999999998\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0050 - val_loss: 0.0079\n",
      "0.9047499999999999\n",
      "Total score: 0.9047499999999999\n",
      "current_patience:  2\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0049 - val_loss: 0.0078\n",
      "0.90425\n",
      "Total score: 0.90425\n",
      "current_patience:  3\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.00025\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0050 - val_loss: 0.0077\n",
      "0.9182499999999999\n",
      "Total score: 0.9182499999999999\n",
      "current_patience:  4\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.00025\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0049 - val_loss: 0.0080\n",
      "0.9089999999999999\n",
      "Total score: 0.9089999999999999\n",
      "current_patience:  5\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.00025\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0049 - val_loss: 0.0077\n",
      "0.9157499999999998\n",
      "Total score: 0.9157499999999998\n",
      "current_patience:  6\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.000125\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0050 - val_loss: 0.0077\n",
      "0.91975\n",
      "Total score: 0.91975\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.000125\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0049 - val_loss: 0.0077\n",
      "0.9172499999999999\n",
      "Total score: 0.9172499999999999\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.000125\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0048 - val_loss: 0.0079\n",
      "0.9182499999999999\n",
      "Total score: 0.9182499999999999\n",
      "current_patience:  2\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.000125\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0048 - val_loss: 0.0078\n",
      "0.9174999999999999\n",
      "Total score: 0.9174999999999999\n",
      "current_patience:  3\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  6.25e-05\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0049 - val_loss: 0.0078\n",
      "0.9162499999999999\n",
      "Total score: 0.9162499999999999\n",
      "current_patience:  4\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  6.25e-05\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0048 - val_loss: 0.0078\n",
      "0.9129999999999999\n",
      "Total score: 0.9129999999999999\n",
      "current_patience:  5\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  6.25e-05\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0048 - val_loss: 0.0078\n",
      "0.92125\n",
      "Total score: 0.92125\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  6.25e-05\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0048 - val_loss: 0.0077\n",
      "0.91875\n",
      "Total score: 0.91875\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  6.25e-05\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0048 - val_loss: 0.0079\n",
      "0.9127500000000001\n",
      "Total score: 0.9127500000000001\n",
      "current_patience:  2\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  6.25e-05\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0048 - val_loss: 0.0079\n",
      "0.9105\n",
      "Total score: 0.9105\n",
      "current_patience:  3\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  3.125e-05\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0048 - val_loss: 0.0078\n",
      "0.9105\n",
      "Total score: 0.9105\n",
      "current_patience:  4\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  3.125e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0048 - val_loss: 0.0078\n",
      "0.9245\n",
      "Total score: 0.9245\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  3.125e-05\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0047 - val_loss: 0.0079\n",
      "0.922\n",
      "Total score: 0.922\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  3.125e-05\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0047 - val_loss: 0.0079\n",
      "0.922\n",
      "Total score: 0.922\n",
      "current_patience:  2\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  3.125e-05\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0048 - val_loss: 0.0079\n",
      "0.91525\n",
      "Total score: 0.91525\n",
      "current_patience:  3\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  1.5625e-05\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0047 - val_loss: 0.0078\n",
      "0.9185000000000001\n",
      "Total score: 0.9185000000000001\n",
      "current_patience:  4\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  1.5625e-05\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0047 - val_loss: 0.0078\n",
      "0.91775\n",
      "Total score: 0.91775\n",
      "current_patience:  5\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  1.5625e-05\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0048 - val_loss: 0.0078\n",
      "0.922\n",
      "Total score: 0.922\n",
      "current_patience:  6\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  7.8125e-06\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0048 - val_loss: 0.0078\n",
      "0.916\n",
      "Total score: 0.916\n",
      "current_patience:  7\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  7.8125e-06\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0048 - val_loss: 0.0078\n",
      "0.9177500000000001\n",
      "Total score: 0.9177500000000001\n",
      "current_patience:  8\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  7.8125e-06\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0047 - val_loss: 0.0079\n",
      "0.9077500000000001\n",
      "Total score: 0.9077500000000001\n",
      "current_patience:  9\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  3.90625e-06\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0047 - val_loss: 0.0078\n",
      "0.92025\n",
      "Total score: 0.92025\n",
      "current_patience:  10\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  3.90625e-06\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0048 - val_loss: 0.0078\n",
      "0.9195\n",
      "Total score: 0.9195\n",
      "current_patience:  11\n",
      "0.8977499999999994\n",
      "0.050000: 0.897750\n",
      "0.9124999999999994\n",
      "0.100000: 0.912500\n",
      "0.9192499999999997\n",
      "0.150000: 0.919250\n",
      "0.9235\n",
      "0.200000: 0.923500\n",
      "0.9245\n",
      "0.250000: 0.924500\n",
      "0.922\n",
      "0.300000: 0.922000\n",
      "0.92175\n",
      "0.350000: 0.921750\n",
      "0.9225\n",
      "0.400000: 0.922500\n",
      "0.9180000000000001\n",
      "0.450000: 0.918000\n",
      "0.9077500000000001\n",
      "0.500000: 0.907750\n",
      "0.9067500000000002\n",
      "0.550000: 0.906750\n",
      "0.8902500000000003\n",
      "0.600000: 0.890250\n",
      "0.8670000000000004\n",
      "0.650000: 0.867000\n",
      "0.8360000000000006\n",
      "0.700000: 0.836000\n",
      "0.7932500000000009\n",
      "0.750000: 0.793250\n",
      "0.7197500000000009\n",
      "0.800000: 0.719750\n",
      "0.590000000000001\n",
      "0.850000: 0.590000\n",
      "0.0\n",
      "0.900000: 0.000000\n",
      "0.0\n",
      "0.950000: 0.000000\n",
      "lr:  0.001\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0360 - val_loss: 0.0178\n",
      "0.6437499999999996\n",
      "Total score: 0.6437499999999996\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0172 - val_loss: 0.0153\n",
      "0.7217499999999997\n",
      "Total score: 0.7217499999999997\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0153 - val_loss: 0.0143\n",
      "0.7682499999999997\n",
      "Total score: 0.7682499999999997\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0142 - val_loss: 0.0134\n",
      "0.7704999999999994\n",
      "Total score: 0.7704999999999994\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0133 - val_loss: 0.0126\n",
      "0.8044999999999994\n",
      "Total score: 0.8044999999999994\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0124 - val_loss: 0.0118\n",
      "0.8377499999999997\n",
      "Total score: 0.8377499999999997\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0115 - val_loss: 0.0110\n",
      "0.8447499999999996\n",
      "Total score: 0.8447499999999996\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0104 - val_loss: 0.0102\n",
      "0.8734999999999995\n",
      "Total score: 0.8734999999999995\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0096 - val_loss: 0.0094\n",
      "0.8999999999999997\n",
      "Total score: 0.8999999999999997\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0087 - val_loss: 0.0089\n",
      "0.8767499999999996\n",
      "Total score: 0.8767499999999996\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0081 - val_loss: 0.0088\n",
      "0.8892499999999995\n",
      "Total score: 0.8892499999999995\n",
      "current_patience:  2\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0076 - val_loss: 0.0083\n",
      "0.8807499999999997\n",
      "Total score: 0.8807499999999997\n",
      "current_patience:  3\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0087 - val_loss: 0.0090\n",
      "0.8944999999999994\n",
      "Total score: 0.8944999999999994\n",
      "current_patience:  4\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0082 - val_loss: 0.0087\n",
      "0.9039999999999998\n",
      "Total score: 0.9039999999999998\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0078 - val_loss: 0.0084\n",
      "0.9164999999999995\n",
      "Total score: 0.9164999999999995\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0075 - val_loss: 0.0086\n",
      "0.9017499999999995\n",
      "Total score: 0.9017499999999995\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0073 - val_loss: 0.0083\n",
      "0.9002499999999994\n",
      "Total score: 0.9002499999999994\n",
      "current_patience:  2\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 63s 6ms/step - loss: 0.0071 - val_loss: 0.0084\n",
      "0.8949999999999996\n",
      "Total score: 0.8949999999999996\n",
      "current_patience:  3\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.00025\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0075 - val_loss: 0.0086\n",
      "0.9022499999999996\n",
      "Total score: 0.9022499999999996\n",
      "current_patience:  4\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.00025\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0073 - val_loss: 0.0083\n",
      "0.9034999999999996\n",
      "Total score: 0.9034999999999996\n",
      "current_patience:  5\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.00025\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0072 - val_loss: 0.0083\n",
      "0.9154999999999999\n",
      "Total score: 0.9154999999999999\n",
      "current_patience:  6\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.000125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0075 - val_loss: 0.0084\n",
      "0.9119999999999996\n",
      "Total score: 0.9119999999999996\n",
      "current_patience:  7\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.000125\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0074 - val_loss: 0.0085\n",
      "0.9007499999999996\n",
      "Total score: 0.9007499999999996\n",
      "current_patience:  8\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.000125\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0073 - val_loss: 0.0085\n",
      "0.9094999999999996\n",
      "Total score: 0.9094999999999996\n",
      "current_patience:  9\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  6.25e-05\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0075 - val_loss: 0.0085\n",
      "0.9119999999999996\n",
      "Total score: 0.9119999999999996\n",
      "current_patience:  10\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  6.25e-05\n",
      "11200/11200 [==============================] - 62s 6ms/step - loss: 0.0074 - val_loss: 0.0085\n",
      "0.9134999999999996\n",
      "Total score: 0.9134999999999996\n",
      "current_patience:  11\n",
      "0.8664999999999992\n",
      "0.050000: 0.866500\n",
      "0.8962499999999994\n",
      "0.100000: 0.896250\n",
      "0.9024999999999994\n",
      "0.150000: 0.902500\n",
      "0.9134999999999995\n",
      "0.200000: 0.913500\n",
      "0.9164999999999995\n",
      "0.250000: 0.916500\n",
      "0.9139999999999996\n",
      "0.300000: 0.914000\n",
      "0.9057499999999998\n",
      "0.350000: 0.905750\n",
      "0.9064999999999998\n",
      "0.400000: 0.906500\n",
      "0.8927499999999998\n",
      "0.450000: 0.892750\n",
      "0.8865\n",
      "0.500000: 0.886500\n",
      "0.8705000000000002\n",
      "0.550000: 0.870500\n",
      "0.8325000000000007\n",
      "0.600000: 0.832500\n",
      "0.7805000000000006\n",
      "0.650000: 0.780500\n",
      "0.729250000000001\n",
      "0.700000: 0.729250\n",
      "0.0\n",
      "0.750000: 0.000000\n",
      "0.0\n",
      "0.800000: 0.000000\n",
      "0.0\n",
      "0.850000: 0.000000\n",
      "0.0\n",
      "0.900000: 0.000000\n",
      "0.0\n",
      "0.950000: 0.000000\n",
      "kernel_size:  7\n",
      "drop_rate:  0.2\n",
      "filter_num:  32\n",
      "use_lstm:  False\n",
      "varyLR:  True\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "data (InputLayer)               (None, None, 2)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv1D)           (None, None, 32)     480         data[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, None, 32)     128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, None, 32)     0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv1D)           (None, None, 32)     7200        dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, None, 32)     128         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling1D)            (None, None, 32)     0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv1D)           (None, None, 32)     7200        pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, None, 32)     128         block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, None, 32)     0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv1D)           (None, None, 32)     7200        dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, None, 32)     128         block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "pool2 (MaxPooling1D)            (None, None, 32)     0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv1D)           (None, None, 64)     14400       pool2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, None, 64)     256         block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, None, 64)     0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv1D)           (None, None, 64)     28736       dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, None, 64)     256         block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "pool3 (MaxPooling1D)            (None, None, 64)     0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv1D)           (None, None, 64)     28736       pool3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, None, 64)     256         block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, None, 64)     0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv1D)           (None, None, 64)     28736       dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, None, 64)     256         block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "pool4 (MaxPooling1D)            (None, None, 64)     0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv1D)           (None, None, 128)    57472       pool4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, None, 128)    512         block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, None, 128)    0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv1D)           (None, None, 128)    114816      dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, None, 128)    512         block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "pool5 (MaxPooling1D)            (None, None, 128)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block6_conv1 (Conv1D)           (None, None, 128)    114816      pool5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, None, 128)    512         block6_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, None, 128)    0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block6_conv2 (Conv1D)           (None, None, 128)    114816      dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, None, 128)    512         block6_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "pool6 (MaxPooling1D)            (None, None, 128)    0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block7_conv1 (Conv1D)           (None, None, 256)    229632      pool6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, None, 256)    1024        block7_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, None, 256)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block7_conv2 (Conv1D)           (None, None, 256)    459008      dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, None, 256)    1024        block7_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "pool7 (MaxPooling1D)            (None, None, 256)    0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block8_conv1 (Conv1D)           (None, None, 256)    459008      pool7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, None, 256)    1024        block8_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, None, 256)    0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block8_conv2 (Conv1D)           (None, None, 256)    459008      dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, None, 256)    1024        block8_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "pool8 (MaxPooling1D)            (None, None, 256)    0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block9_conv1 (Conv1D)           (None, None, 512)    918016      pool8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, None, 512)    2048        block9_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, None, 512)    0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block9_conv2 (Conv1D)           (None, None, 512)    1835520     dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, None, 512)    2048        block9_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "pool9 (MaxPooling1D)            (None, None, 512)    0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block10_conv1 (Conv1D)          (None, None, 512)    1835520     pool9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, None, 512)    2048        block10_conv1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, None, 512)    0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block10_conv2 (Conv1D)          (None, None, 512)    1835520     dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, None, 512)    2048        block10_conv2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_10 (UpSampling1D) (None, None, 512)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up9 (Conv1D)                    (None, None, 512)    262656      up_sampling1d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, None, 1024)   0           up9[0][0]                        \n",
      "                                                                 batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "deconv9_conv1 (Conv1D)          (None, None, 256)    1835264     concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, None, 256)    1024        deconv9_conv1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, None, 256)    0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "deconv9_conv2 (Conv1D)          (None, None, 256)    459008      dropout_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, None, 256)    1024        deconv9_conv2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_11 (UpSampling1D) (None, None, 256)    0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up8 (Conv1D)                    (None, None, 256)    65792       up_sampling1d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, None, 512)    0           up8[0][0]                        \n",
      "                                                                 batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "deconv8_conv1 (Conv1D)          (None, None, 256)    917760      concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, None, 256)    1024        deconv8_conv1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, None, 256)    0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "deconv8_conv2 (Conv1D)          (None, None, 256)    459008      dropout_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, None, 256)    1024        deconv8_conv2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_12 (UpSampling1D) (None, None, 256)    0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up7 (Conv1D)                    (None, None, 256)    65792       up_sampling1d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, None, 512)    0           up7[0][0]                        \n",
      "                                                                 batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "deconv7_conv1 (Conv1D)          (None, None, 256)    917760      concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, None, 256)    1024        deconv7_conv1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, None, 256)    0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "deconv7_conv2 (Conv1D)          (None, None, 256)    459008      dropout_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, None, 256)    1024        deconv7_conv2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_13 (UpSampling1D) (None, None, 256)    0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up6 (Conv1D)                    (None, None, 128)    32896       up_sampling1d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, None, 256)    0           up6[0][0]                        \n",
      "                                                                 batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "deconv6_conv1 (Conv1D)          (None, None, 32)     57376       concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, None, 32)     128         deconv6_conv1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, None, 32)     0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "deconv6_conv2 (Conv1D)          (None, None, 32)     7200        dropout_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, None, 32)     128         deconv6_conv2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_14 (UpSampling1D) (None, None, 32)     0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up5 (Conv1D)                    (None, None, 128)    4224        up_sampling1d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, None, 256)    0           up5[0][0]                        \n",
      "                                                                 batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "deconv5_conv1 (Conv1D)          (None, None, 32)     57376       concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, None, 32)     128         deconv5_conv1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)            (None, None, 32)     0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "deconv5_conv2 (Conv1D)          (None, None, 32)     7200        dropout_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, None, 32)     128         deconv5_conv2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_15 (UpSampling1D) (None, None, 32)     0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up4 (Conv1D)                    (None, None, 64)     2112        up_sampling1d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, None, 128)    0           up4[0][0]                        \n",
      "                                                                 batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "deconv4_conv1 (Conv1D)          (None, None, 32)     28704       concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, None, 32)     128         deconv4_conv1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, None, 32)     0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "deconv4_conv2 (Conv1D)          (None, None, 32)     7200        dropout_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, None, 32)     128         deconv4_conv2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_16 (UpSampling1D) (None, None, 32)     0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up3 (Conv1D)                    (None, None, 64)     2112        up_sampling1d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, None, 128)    0           up3[0][0]                        \n",
      "                                                                 batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "deconv3_conv1 (Conv1D)          (None, None, 32)     28704       concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, None, 32)     128         deconv3_conv1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)            (None, None, 32)     0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "deconv3_conv2 (Conv1D)          (None, None, 32)     7200        dropout_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, None, 32)     128         deconv3_conv2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_17 (UpSampling1D) (None, None, 32)     0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up2 (Conv1D)                    (None, None, 32)     1056        up_sampling1d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, None, 64)     0           up2[0][0]                        \n",
      "                                                                 batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "deconv2_conv1 (Conv1D)          (None, None, 32)     14368       concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, None, 32)     128         deconv2_conv1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, None, 32)     0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "deconv2_conv2 (Conv1D)          (None, None, 32)     7200        dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, None, 32)     128         deconv2_conv2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_18 (UpSampling1D) (None, None, 32)     0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up1 (Conv1D)                    (None, None, 32)     1056        up_sampling1d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, None, 64)     0           up1[0][0]                        \n",
      "                                                                 batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "deconv1_conv1 (Conv1D)          (None, None, 32)     14368       concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, None, 32)     128         deconv1_conv1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, None, 32)     0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "deconv1_conv2 (Conv1D)          (None, None, 32)     7200        dropout_38[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, None, 32)     128         deconv1_conv2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv10 (Conv1D)                 (None, None, 1)      33          batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Conv1D)            (None, None, 1)      2           conv10[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 14,309,027\n",
      "Trainable params: 14,297,251\n",
      "Non-trainable params: 11,776\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape (2000, 5000, 1)\n",
      "Y.shape (2000, 5000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Roaming\\Python\\Python35\\site-packages\\sklearn\\preprocessing\\data.py:180: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\dell\\AppData\\Roaming\\Python\\Python35\\site-packages\\sklearn\\preprocessing\\data.py:197: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 5000, 2)\n",
      "(2000, 5000, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validating...\n",
      "lr:  0.001\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 99s 9ms/step - loss: 0.1899 - val_loss: 0.1555\n",
      "0.5627499999999992\n",
      "Total score: 0.5627499999999992\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 66s 6ms/step - loss: 0.1275 - val_loss: 0.1026\n",
      "0.7259999999999991\n",
      "Total score: 0.7259999999999991\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0826 - val_loss: 0.0661\n",
      "0.4922499999999991\n",
      "Total score: 0.4922499999999991\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0528 - val_loss: 0.0432\n",
      "0.8674999999999997\n",
      "Total score: 0.8674999999999997\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0346 - val_loss: 0.0292\n",
      "0.8874999999999998\n",
      "Total score: 0.8874999999999998\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0237 - val_loss: 0.0212\n",
      "0.8932499999999998\n",
      "Total score: 0.8932499999999998\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0171 - val_loss: 0.0165\n",
      "0.8887499999999998\n",
      "Total score: 0.8887499999999998\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0129 - val_loss: 0.0135\n",
      "0.8834999999999998\n",
      "Total score: 0.8834999999999998\n",
      "current_patience:  2\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0103 - val_loss: 0.0115\n",
      "0.8949999999999999\n",
      "Total score: 0.8949999999999999\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0085 - val_loss: 0.0103\n",
      "0.9012499999999999\n",
      "Total score: 0.9012499999999999\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0073 - val_loss: 0.0094\n",
      "0.9022499999999996\n",
      "Total score: 0.9022499999999996\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0065 - val_loss: 0.0093\n",
      "0.90625\n",
      "Total score: 0.90625\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0059 - val_loss: 0.0088\n",
      "0.9022500000000001\n",
      "Total score: 0.9022500000000001\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0054 - val_loss: 0.0090\n",
      "0.90125\n",
      "Total score: 0.90125\n",
      "current_patience:  2\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0051 - val_loss: 0.0087\n",
      "0.90775\n",
      "Total score: 0.90775\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0049 - val_loss: 0.0091\n",
      "0.8874999999999997\n",
      "Total score: 0.8874999999999997\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0047 - val_loss: 0.0085\n",
      "0.9044999999999997\n",
      "Total score: 0.9044999999999997\n",
      "current_patience:  2\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0045 - val_loss: 0.0086\n",
      "0.9102499999999999\n",
      "Total score: 0.9102499999999999\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0043 - val_loss: 0.0084\n",
      "0.9155\n",
      "Total score: 0.9155\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0041 - val_loss: 0.0089\n",
      "0.9122499999999998\n",
      "Total score: 0.9122499999999998\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0040 - val_loss: 0.0089\n",
      "0.9264999999999999\n",
      "Total score: 0.9264999999999999\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0039 - val_loss: 0.0090\n",
      "0.9185\n",
      "Total score: 0.9185\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0038 - val_loss: 0.0088\n",
      "0.9139999999999999\n",
      "Total score: 0.9139999999999999\n",
      "current_patience:  2\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0036 - val_loss: 0.0091\n",
      "0.9144999999999999\n",
      "Total score: 0.9144999999999999\n",
      "current_patience:  3\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0036 - val_loss: 0.0088\n",
      "0.9175\n",
      "Total score: 0.9175\n",
      "current_patience:  4\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 66s 6ms/step - loss: 0.0034 - val_loss: 0.0086\n",
      "0.93425\n",
      "Total score: 0.93425\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0034 - val_loss: 0.0087\n",
      "0.91675\n",
      "Total score: 0.91675\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0033 - val_loss: 0.0087\n",
      "0.92675\n",
      "Total score: 0.92675\n",
      "current_patience:  2\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0032 - val_loss: 0.0086\n",
      "0.91775\n",
      "Total score: 0.91775\n",
      "current_patience:  3\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.00025\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0033 - val_loss: 0.0086\n",
      "0.9252499999999999\n",
      "Total score: 0.9252499999999999\n",
      "current_patience:  4\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.00025\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0032 - val_loss: 0.0087\n",
      "0.932\n",
      "Total score: 0.932\n",
      "current_patience:  5\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.00025\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0031 - val_loss: 0.0088\n",
      "0.9279999999999998\n",
      "Total score: 0.9279999999999998\n",
      "current_patience:  6\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.000125\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0032 - val_loss: 0.0085\n",
      "0.92825\n",
      "Total score: 0.92825\n",
      "current_patience:  7\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.000125\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0032 - val_loss: 0.0087\n",
      "0.9275\n",
      "Total score: 0.9275\n",
      "current_patience:  8\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.000125\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0031 - val_loss: 0.0087\n",
      "0.9257500000000001\n",
      "Total score: 0.9257500000000001\n",
      "current_patience:  9\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  6.25e-05\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0032 - val_loss: 0.0086\n",
      "0.9275\n",
      "Total score: 0.9275\n",
      "current_patience:  10\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  6.25e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0032 - val_loss: 0.0085\n",
      "0.9269999999999999\n",
      "Total score: 0.9269999999999999\n",
      "current_patience:  11\n",
      "0.8969999999999994\n",
      "0.050000: 0.897000\n",
      "0.9117499999999995\n",
      "0.100000: 0.911750\n",
      "0.9217499999999997\n",
      "0.150000: 0.921750\n",
      "0.9304999999999999\n",
      "0.200000: 0.930500\n",
      "0.93425\n",
      "0.250000: 0.934250\n",
      "0.93175\n",
      "0.300000: 0.931750\n",
      "0.9247500000000001\n",
      "0.350000: 0.924750\n",
      "0.9237500000000002\n",
      "0.400000: 0.923750\n",
      "0.9245000000000002\n",
      "0.450000: 0.924500\n",
      "0.9217500000000001\n",
      "0.500000: 0.921750\n",
      "0.9145000000000002\n",
      "0.550000: 0.914500\n",
      "0.9100000000000003\n",
      "0.600000: 0.910000\n",
      "0.8945000000000003\n",
      "0.650000: 0.894500\n",
      "0.8842500000000004\n",
      "0.700000: 0.884250\n",
      "0.8645000000000006\n",
      "0.750000: 0.864500\n",
      "0.8162500000000008\n",
      "0.800000: 0.816250\n",
      "0.7425000000000012\n",
      "0.850000: 0.742500\n",
      "0.5577500000000009\n",
      "0.900000: 0.557750\n",
      "0.14549999999999982\n",
      "0.950000: 0.145500\n",
      "lr:  0.001\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.1917 - val_loss: 0.1575\n",
      "0.6984999999999993\n",
      "Total score: 0.6984999999999993\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.1288 - val_loss: 0.1040\n",
      "0.7194999999999991\n",
      "Total score: 0.7194999999999991\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0836 - val_loss: 0.0674\n",
      "0.5934999999999989\n",
      "Total score: 0.5934999999999989\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0536 - val_loss: 0.0441\n",
      "0.8499999999999999\n",
      "Total score: 0.8499999999999999\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0351 - val_loss: 0.0303\n",
      "0.8684999999999999\n",
      "Total score: 0.8684999999999999\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0241 - val_loss: 0.0221\n",
      "0.8732499999999999\n",
      "Total score: 0.8732499999999999\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0174 - val_loss: 0.0172\n",
      "0.87875\n",
      "Total score: 0.87875\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0133 - val_loss: 0.0141\n",
      "0.8954999999999999\n",
      "Total score: 0.8954999999999999\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0106 - val_loss: 0.0120\n",
      "0.9065000000000001\n",
      "Total score: 0.9065000000000001\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0088 - val_loss: 0.0112\n",
      "0.907\n",
      "Total score: 0.907\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0075 - val_loss: 0.0109\n",
      "0.90625\n",
      "Total score: 0.90625\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0067 - val_loss: 0.0099\n",
      "0.90575\n",
      "Total score: 0.90575\n",
      "current_patience:  2\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0061 - val_loss: 0.0093\n",
      "0.9109999999999999\n",
      "Total score: 0.9109999999999999\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0055 - val_loss: 0.0097\n",
      "0.9035\n",
      "Total score: 0.9035\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0052 - val_loss: 0.0098\n",
      "0.90125\n",
      "Total score: 0.90125\n",
      "current_patience:  2\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0049 - val_loss: 0.0094\n",
      "0.9105\n",
      "Total score: 0.9105\n",
      "current_patience:  3\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0054 - val_loss: 0.0095\n",
      "0.9107499999999998\n",
      "Total score: 0.9107499999999998\n",
      "current_patience:  4\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0050 - val_loss: 0.0094\n",
      "0.9222499999999999\n",
      "Total score: 0.9222499999999999\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0048 - val_loss: 0.0097\n",
      "0.9067499999999998\n",
      "Total score: 0.9067499999999998\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0047 - val_loss: 0.0094\n",
      "0.91375\n",
      "Total score: 0.91375\n",
      "current_patience:  2\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0044 - val_loss: 0.0096\n",
      "0.9175\n",
      "Total score: 0.9175\n",
      "current_patience:  3\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.00025\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0047 - val_loss: 0.0095\n",
      "0.92275\n",
      "Total score: 0.92275\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.00025\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0046 - val_loss: 0.0096\n",
      "0.9294999999999999\n",
      "Total score: 0.9294999999999999\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.00025\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0045 - val_loss: 0.0098\n",
      "0.9157499999999998\n",
      "Total score: 0.9157499999999998\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.00025\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0043 - val_loss: 0.0097\n",
      "0.91425\n",
      "Total score: 0.91425\n",
      "current_patience:  2\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.00025\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0042 - val_loss: 0.0096\n",
      "0.9184999999999998\n",
      "Total score: 0.9184999999999998\n",
      "current_patience:  3\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.000125\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0044 - val_loss: 0.0098\n",
      "0.9242499999999998\n",
      "Total score: 0.9242499999999998\n",
      "current_patience:  4\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.000125\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0043 - val_loss: 0.0096\n",
      "0.9192499999999998\n",
      "Total score: 0.9192499999999998\n",
      "current_patience:  5\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.000125\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0042 - val_loss: 0.0097\n",
      "0.9262499999999999\n",
      "Total score: 0.9262499999999999\n",
      "current_patience:  6\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  6.25e-05\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0044 - val_loss: 0.0096\n",
      "0.9292499999999998\n",
      "Total score: 0.9292499999999998\n",
      "current_patience:  7\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  6.25e-05\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0043 - val_loss: 0.0097\n",
      "0.9267499999999999\n",
      "Total score: 0.9267499999999999\n",
      "current_patience:  8\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  6.25e-05\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0043 - val_loss: 0.0096\n",
      "0.9267499999999999\n",
      "Total score: 0.9267499999999999\n",
      "current_patience:  9\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  3.125e-05\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0044 - val_loss: 0.0096\n",
      "0.9292499999999998\n",
      "Total score: 0.9292499999999998\n",
      "current_patience:  10\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  3.125e-05\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0043 - val_loss: 0.0098\n",
      "0.9277499999999997\n",
      "Total score: 0.9277499999999997\n",
      "current_patience:  11\n",
      "0.9017499999999994\n",
      "0.050000: 0.901750\n",
      "0.9169999999999997\n",
      "0.100000: 0.917000\n",
      "0.9257499999999997\n",
      "0.150000: 0.925750\n",
      "0.9279999999999998\n",
      "0.200000: 0.928000\n",
      "0.9294999999999999\n",
      "0.250000: 0.929500\n",
      "0.9267499999999999\n",
      "0.300000: 0.926750\n",
      "0.9249999999999998\n",
      "0.350000: 0.925000\n",
      "0.9249999999999998\n",
      "0.400000: 0.925000\n",
      "0.9229999999999999\n",
      "0.450000: 0.923000\n",
      "0.9175\n",
      "0.500000: 0.917500\n",
      "0.9077500000000001\n",
      "0.550000: 0.907750\n",
      "0.8955000000000003\n",
      "0.600000: 0.895500\n",
      "0.8865000000000003\n",
      "0.650000: 0.886500\n",
      "0.8632500000000004\n",
      "0.700000: 0.863250\n",
      "0.8247500000000008\n",
      "0.750000: 0.824750\n",
      "0.7792500000000008\n",
      "0.800000: 0.779250\n",
      "0.674500000000001\n",
      "0.850000: 0.674500\n",
      "0.3992500000000004\n",
      "0.900000: 0.399250\n",
      "0.07075000000000004\n",
      "0.950000: 0.070750\n",
      "lr:  0.001\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.1917 - val_loss: 0.1570\n",
      "0.6897499999999992\n",
      "Total score: 0.6897499999999992\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.1287 - val_loss: 0.1033\n",
      "0.7404999999999993\n",
      "Total score: 0.7404999999999993\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0836 - val_loss: 0.0666\n",
      "0.5287499999999988\n",
      "Total score: 0.5287499999999988\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0536 - val_loss: 0.0433\n",
      "0.8574999999999996\n",
      "Total score: 0.8574999999999996\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0352 - val_loss: 0.0291\n",
      "0.8682499999999999\n",
      "Total score: 0.8682499999999999\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0242 - val_loss: 0.0211\n",
      "0.8862499999999995\n",
      "Total score: 0.8862499999999995\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0175 - val_loss: 0.0165\n",
      "0.8749999999999999\n",
      "Total score: 0.8749999999999999\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0133 - val_loss: 0.0131\n",
      "0.885\n",
      "Total score: 0.885\n",
      "current_patience:  2\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0106 - val_loss: 0.0108\n",
      "0.8805000000000001\n",
      "Total score: 0.8805000000000001\n",
      "current_patience:  3\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0182 - val_loss: 0.0173\n",
      "0.888\n",
      "Total score: 0.888\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0150 - val_loss: 0.0148\n",
      "0.8775\n",
      "Total score: 0.8775\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0125 - val_loss: 0.0130\n",
      "0.8965\n",
      "Total score: 0.8965\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0107 - val_loss: 0.0117\n",
      "0.88925\n",
      "Total score: 0.88925\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0094 - val_loss: 0.0104\n",
      "0.9064999999999999\n",
      "Total score: 0.9064999999999999\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0084 - val_loss: 0.0099\n",
      "0.89575\n",
      "Total score: 0.89575\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0076 - val_loss: 0.0090\n",
      "0.9030000000000001\n",
      "Total score: 0.9030000000000001\n",
      "current_patience:  2\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0069 - val_loss: 0.0085\n",
      "0.9119999999999999\n",
      "Total score: 0.9119999999999999\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0064 - val_loss: 0.0085\n",
      "0.9030000000000002\n",
      "Total score: 0.9030000000000002\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0060 - val_loss: 0.0084\n",
      "0.9052500000000002\n",
      "Total score: 0.9052500000000002\n",
      "current_patience:  2\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0057 - val_loss: 0.0079\n",
      "0.9047499999999999\n",
      "Total score: 0.9047499999999999\n",
      "current_patience:  3\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.00025\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0064 - val_loss: 0.0085\n",
      "0.9130000000000001\n",
      "Total score: 0.9130000000000001\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.00025\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0060 - val_loss: 0.0082\n",
      "0.9215000000000001\n",
      "Total score: 0.9215000000000001\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.00025\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0058 - val_loss: 0.0082\n",
      "0.9065000000000001\n",
      "Total score: 0.9065000000000001\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.00025\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0056 - val_loss: 0.0082\n",
      "0.9150000000000001\n",
      "Total score: 0.9150000000000001\n",
      "current_patience:  2\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.00025\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0054 - val_loss: 0.0081\n",
      "0.9132499999999999\n",
      "Total score: 0.9132499999999999\n",
      "current_patience:  3\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.000125\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0058 - val_loss: 0.0083\n",
      "0.9139999999999999\n",
      "Total score: 0.9139999999999999\n",
      "current_patience:  4\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.000125\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0056 - val_loss: 0.0083\n",
      "0.9175\n",
      "Total score: 0.9175\n",
      "current_patience:  5\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.000125\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0055 - val_loss: 0.0083\n",
      "0.9200000000000002\n",
      "Total score: 0.9200000000000002\n",
      "current_patience:  6\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  6.25e-05\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0058 - val_loss: 0.0083\n",
      "0.9172500000000001\n",
      "Total score: 0.9172500000000001\n",
      "current_patience:  7\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  6.25e-05\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0057 - val_loss: 0.0083\n",
      "0.91825\n",
      "Total score: 0.91825\n",
      "current_patience:  8\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  6.25e-05\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0056 - val_loss: 0.0083\n",
      "0.9155000000000001\n",
      "Total score: 0.9155000000000001\n",
      "current_patience:  9\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  3.125e-05\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0058 - val_loss: 0.0083\n",
      "0.9137500000000002\n",
      "Total score: 0.9137500000000002\n",
      "current_patience:  10\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  3.125e-05\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0057 - val_loss: 0.0083\n",
      "0.9145\n",
      "Total score: 0.9145\n",
      "current_patience:  11\n",
      "0.8902499999999995\n",
      "0.050000: 0.890250\n",
      "0.91475\n",
      "0.100000: 0.914750\n",
      "0.9155\n",
      "0.150000: 0.915500\n",
      "0.92\n",
      "0.200000: 0.920000\n",
      "0.9215000000000001\n",
      "0.250000: 0.921500\n",
      "0.9195000000000002\n",
      "0.300000: 0.919500\n",
      "0.9102500000000002\n",
      "0.350000: 0.910250\n",
      "0.9052500000000002\n",
      "0.400000: 0.905250\n",
      "0.9037500000000002\n",
      "0.450000: 0.903750\n",
      "0.9010000000000002\n",
      "0.500000: 0.901000\n",
      "0.8957500000000002\n",
      "0.550000: 0.895750\n",
      "0.8852500000000002\n",
      "0.600000: 0.885250\n",
      "0.8772500000000004\n",
      "0.650000: 0.877250\n",
      "0.8540000000000005\n",
      "0.700000: 0.854000\n",
      "0.8227500000000005\n",
      "0.750000: 0.822750\n",
      "0.7605000000000005\n",
      "0.800000: 0.760500\n",
      "0.642250000000001\n",
      "0.850000: 0.642250\n",
      "0.39375000000000027\n",
      "0.900000: 0.393750\n",
      "0.046750000000000014\n",
      "0.950000: 0.046750\n",
      "lr:  0.001\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.1917 - val_loss: 0.1577\n",
      "0.47149999999999936\n",
      "Total score: 0.47149999999999936\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.1290 - val_loss: 0.1038\n",
      "0.7172499999999989\n",
      "Total score: 0.7172499999999989\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0838 - val_loss: 0.0668\n",
      "0.42149999999999993\n",
      "Total score: 0.42149999999999993\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0538 - val_loss: 0.0429\n",
      "0.8527499999999997\n",
      "Total score: 0.8527499999999997\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0354 - val_loss: 0.0292\n",
      "0.8522499999999996\n",
      "Total score: 0.8522499999999996\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0244 - val_loss: 0.0208\n",
      "0.8727499999999999\n",
      "Total score: 0.8727499999999999\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0176 - val_loss: 0.0157\n",
      "0.8557499999999995\n",
      "Total score: 0.8557499999999995\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0135 - val_loss: 0.0128\n",
      "0.8869999999999999\n",
      "Total score: 0.8869999999999999\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0109 - val_loss: 0.0109\n",
      "0.8837499999999998\n",
      "Total score: 0.8837499999999998\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0091 - val_loss: 0.0097\n",
      "0.8872499999999995\n",
      "Total score: 0.8872499999999995\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0078 - val_loss: 0.0100\n",
      "0.8869999999999999\n",
      "Total score: 0.8869999999999999\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0069 - val_loss: 0.0085\n",
      "0.9064999999999998\n",
      "Total score: 0.9064999999999998\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0063 - val_loss: 0.0082\n",
      "0.8954999999999997\n",
      "Total score: 0.8954999999999997\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0059 - val_loss: 0.0079\n",
      "0.8949999999999999\n",
      "Total score: 0.8949999999999999\n",
      "current_patience:  2\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0055 - val_loss: 0.0093\n",
      "0.8914999999999997\n",
      "Total score: 0.8914999999999997\n",
      "current_patience:  3\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0061 - val_loss: 0.0083\n",
      "0.9024999999999999\n",
      "Total score: 0.9024999999999999\n",
      "current_patience:  4\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0058 - val_loss: 0.0086\n",
      "0.9064999999999998\n",
      "Total score: 0.9064999999999998\n",
      "current_patience:  5\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0055 - val_loss: 0.0084\n",
      "0.8944999999999997\n",
      "Total score: 0.8944999999999997\n",
      "current_patience:  6\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.00025\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0061 - val_loss: 0.0084\n",
      "0.9094999999999999\n",
      "Total score: 0.9094999999999999\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.00025\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0058 - val_loss: 0.0086\n",
      "0.9015\n",
      "Total score: 0.9015\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.00025\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0056 - val_loss: 0.0081\n",
      "0.9057499999999998\n",
      "Total score: 0.9057499999999998\n",
      "current_patience:  2\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.00025\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0054 - val_loss: 0.0082\n",
      "0.9154999999999999\n",
      "Total score: 0.9154999999999999\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.00025\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0053 - val_loss: 0.0083\n",
      "0.9089999999999998\n",
      "Total score: 0.9089999999999998\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.00025\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0051 - val_loss: 0.0084\n",
      "0.9052499999999998\n",
      "Total score: 0.9052499999999998\n",
      "current_patience:  2\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.00025\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0050 - val_loss: 0.0084\n",
      "0.91275\n",
      "Total score: 0.91275\n",
      "current_patience:  3\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.000125\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0052 - val_loss: 0.0083\n",
      "0.9159999999999998\n",
      "Total score: 0.9159999999999998\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.000125\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0051 - val_loss: 0.0084\n",
      "0.89925\n",
      "Total score: 0.89925\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.000125\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0050 - val_loss: 0.0085\n",
      "0.9097499999999996\n",
      "Total score: 0.9097499999999996\n",
      "current_patience:  2\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.000125\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0049 - val_loss: 0.0084\n",
      "0.9159999999999998\n",
      "Total score: 0.9159999999999998\n",
      "current_patience:  3\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  6.25e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0051 - val_loss: 0.0084\n",
      "0.9109999999999999\n",
      "Total score: 0.9109999999999999\n",
      "current_patience:  4\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  6.25e-05\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0051 - val_loss: 0.0084\n",
      "0.9104999999999999\n",
      "Total score: 0.9104999999999999\n",
      "current_patience:  5\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  6.25e-05\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0050 - val_loss: 0.0083\n",
      "0.9104999999999999\n",
      "Total score: 0.9104999999999999\n",
      "current_patience:  6\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  3.125e-05\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0051 - val_loss: 0.0083\n",
      "0.9152499999999999\n",
      "Total score: 0.9152499999999999\n",
      "current_patience:  7\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  3.125e-05\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0051 - val_loss: 0.0083\n",
      "0.9109999999999998\n",
      "Total score: 0.9109999999999998\n",
      "current_patience:  8\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  3.125e-05\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0050 - val_loss: 0.0084\n",
      "0.9067499999999998\n",
      "Total score: 0.9067499999999998\n",
      "current_patience:  9\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  1.5625e-05\n",
      "11200/11200 [==============================] - 66s 6ms/step - loss: 0.0051 - val_loss: 0.0084\n",
      "0.9102499999999999\n",
      "Total score: 0.9102499999999999\n",
      "current_patience:  10\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  1.5625e-05\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0051 - val_loss: 0.0083\n",
      "0.9117499999999998\n",
      "Total score: 0.9117499999999998\n",
      "current_patience:  11\n",
      "0.8762499999999993\n",
      "0.050000: 0.876250\n",
      "0.8919999999999995\n",
      "0.100000: 0.892000\n",
      "0.9084999999999996\n",
      "0.150000: 0.908500\n",
      "0.9129999999999998\n",
      "0.200000: 0.913000\n",
      "0.9159999999999998\n",
      "0.250000: 0.916000\n",
      "0.9132499999999999\n",
      "0.300000: 0.913250\n",
      "0.9155\n",
      "0.350000: 0.915500\n",
      "0.9185000000000001\n",
      "0.400000: 0.918500\n",
      "0.91825\n",
      "0.450000: 0.918250\n",
      "0.9145000000000002\n",
      "0.500000: 0.914500\n",
      "0.9082500000000002\n",
      "0.550000: 0.908250\n",
      "0.8970000000000004\n",
      "0.600000: 0.897000\n",
      "0.8745000000000006\n",
      "0.650000: 0.874500\n",
      "0.8592500000000005\n",
      "0.700000: 0.859250\n",
      "0.8310000000000008\n",
      "0.750000: 0.831000\n",
      "0.7847500000000008\n",
      "0.800000: 0.784750\n",
      "0.6740000000000009\n",
      "0.850000: 0.674000\n",
      "0.38775000000000004\n",
      "0.900000: 0.387750\n",
      "0.04100000000000002\n",
      "0.950000: 0.041000\n",
      "lr:  0.001\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 66s 6ms/step - loss: 0.1917 - val_loss: 0.1569\n",
      "0.6762499999999995\n",
      "Total score: 0.6762499999999995\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.1288 - val_loss: 0.1035\n",
      "0.7524999999999994\n",
      "Total score: 0.7524999999999994\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 68s 6ms/step - loss: 0.0835 - val_loss: 0.0665\n",
      "0.5597499999999992\n",
      "Total score: 0.5597499999999992\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 66s 6ms/step - loss: 0.0535 - val_loss: 0.0432\n",
      "0.8599999999999994\n",
      "Total score: 0.8599999999999994\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0351 - val_loss: 0.0295\n",
      "0.8777499999999998\n",
      "Total score: 0.8777499999999998\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0241 - val_loss: 0.0214\n",
      "0.8884999999999995\n",
      "Total score: 0.8884999999999995\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0174 - val_loss: 0.0163\n",
      "0.8949999999999997\n",
      "Total score: 0.8949999999999997\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0133 - val_loss: 0.0133\n",
      "0.9114999999999996\n",
      "Total score: 0.9114999999999996\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 66s 6ms/step - loss: 0.0106 - val_loss: 0.0116\n",
      "0.9087499999999998\n",
      "Total score: 0.9087499999999998\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0089 - val_loss: 0.0101\n",
      "0.9044999999999999\n",
      "Total score: 0.9044999999999999\n",
      "current_patience:  2\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.001\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0077 - val_loss: 0.0094\n",
      "0.9104999999999999\n",
      "Total score: 0.9104999999999999\n",
      "current_patience:  3\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0107 - val_loss: 0.0121\n",
      "0.9062499999999999\n",
      "Total score: 0.9062499999999999\n",
      "current_patience:  4\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0094 - val_loss: 0.0112\n",
      "0.9222499999999998\n",
      "Total score: 0.9222499999999998\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 66s 6ms/step - loss: 0.0084 - val_loss: 0.0102\n",
      "0.9264999999999998\n",
      "Total score: 0.9264999999999998\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 131s 12ms/step - loss: 0.0076 - val_loss: 0.0096\n",
      "0.9159999999999997\n",
      "Total score: 0.9159999999999997\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0069 - val_loss: 0.0092\n",
      "0.9212499999999996\n",
      "Total score: 0.9212499999999996\n",
      "current_patience:  2\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0064 - val_loss: 0.0094\n",
      "0.9307499999999997\n",
      "Total score: 0.9307499999999997\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0061 - val_loss: 0.0090\n",
      "0.9152499999999998\n",
      "Total score: 0.9152499999999998\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0056 - val_loss: 0.0088\n",
      "0.9182499999999998\n",
      "Total score: 0.9182499999999998\n",
      "current_patience:  2\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.0005\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0054 - val_loss: 0.0085\n",
      "0.9292499999999998\n",
      "Total score: 0.9292499999999998\n",
      "current_patience:  3\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.00025\n",
      "11200/11200 [==============================] - 136s 12ms/step - loss: 0.0060 - val_loss: 0.0089\n",
      "0.9369999999999997\n",
      "Total score: 0.9369999999999997\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.00025\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0057 - val_loss: 0.0088\n",
      "0.9322499999999998\n",
      "Total score: 0.9322499999999998\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.00025\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0055 - val_loss: 0.0090\n",
      "0.9257499999999999\n",
      "Total score: 0.9257499999999999\n",
      "current_patience:  2\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.00025\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0053 - val_loss: 0.0088\n",
      "0.9302499999999998\n",
      "Total score: 0.9302499999999998\n",
      "current_patience:  3\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.000125\n",
      "11200/11200 [==============================] - 119s 11ms/step - loss: 0.0057 - val_loss: 0.0089\n",
      "0.9349999999999997\n",
      "Total score: 0.9349999999999997\n",
      "current_patience:  4\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.000125\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0055 - val_loss: 0.0089\n",
      "0.9332499999999997\n",
      "Total score: 0.9332499999999997\n",
      "current_patience:  5\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.000125\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0054 - val_loss: 0.0089\n",
      "0.9397499999999998\n",
      "Total score: 0.9397499999999998\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.000125\n",
      "11200/11200 [==============================] - 182s 16ms/step - loss: 0.0053 - val_loss: 0.0088\n",
      "0.9369999999999998\n",
      "Total score: 0.9369999999999998\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.000125\n",
      "11200/11200 [==============================] - 268s 24ms/step - loss: 0.0052 - val_loss: 0.0087\n",
      "0.9289999999999998\n",
      "Total score: 0.9289999999999998\n",
      "current_patience:  2\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  0.000125\n",
      "11200/11200 [==============================] - 267s 24ms/step - loss: 0.0051 - val_loss: 0.0087\n",
      "0.93275\n",
      "Total score: 0.93275\n",
      "current_patience:  3\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  6.25e-05\n",
      "11200/11200 [==============================] - 267s 24ms/step - loss: 0.0053 - val_loss: 0.0087\n",
      "0.9387499999999999\n",
      "Total score: 0.9387499999999999\n",
      "current_patience:  4\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  6.25e-05\n",
      "11200/11200 [==============================] - 268s 24ms/step - loss: 0.0052 - val_loss: 0.0087\n",
      "0.9374999999999999\n",
      "Total score: 0.9374999999999999\n",
      "current_patience:  5\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  6.25e-05\n",
      "11200/11200 [==============================] - 248s 22ms/step - loss: 0.0052 - val_loss: 0.0087\n",
      "0.9402499999999999\n",
      "Total score: 0.9402499999999999\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  6.25e-05\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0051 - val_loss: 0.0088\n",
      "0.9372499999999999\n",
      "Total score: 0.9372499999999999\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  6.25e-05\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0051 - val_loss: 0.0087\n",
      "0.9312499999999999\n",
      "Total score: 0.9312499999999999\n",
      "current_patience:  2\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  6.25e-05\n",
      "11200/11200 [==============================] - 66s 6ms/step - loss: 0.0050 - val_loss: 0.0087\n",
      "0.9324999999999999\n",
      "Total score: 0.9324999999999999\n",
      "current_patience:  3\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  3.125e-05\n",
      "11200/11200 [==============================] - 66s 6ms/step - loss: 0.0051 - val_loss: 0.0087\n",
      "0.93825\n",
      "Total score: 0.93825\n",
      "current_patience:  4\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  3.125e-05\n",
      "11200/11200 [==============================] - 66s 6ms/step - loss: 0.0051 - val_loss: 0.0087\n",
      "0.9362499999999998\n",
      "Total score: 0.9362499999999998\n",
      "current_patience:  5\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  3.125e-05\n",
      "11200/11200 [==============================] - 66s 6ms/step - loss: 0.0050 - val_loss: 0.0087\n",
      "0.9379999999999998\n",
      "Total score: 0.9379999999999998\n",
      "current_patience:  6\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  1.5625e-05\n",
      "11200/11200 [==============================] - 66s 6ms/step - loss: 0.0051 - val_loss: 0.0087\n",
      "0.935\n",
      "Total score: 0.935\n",
      "current_patience:  7\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  1.5625e-05\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0051 - val_loss: 0.0087\n",
      "0.9395\n",
      "Total score: 0.9395\n",
      "current_patience:  8\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  1.5625e-05\n",
      "11200/11200 [==============================] - 66s 6ms/step - loss: 0.0050 - val_loss: 0.0087\n",
      "0.941\n",
      "Total score: 0.941\n",
      "current_patience:  0\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  1.5625e-05\n",
      "11200/11200 [==============================] - 66s 6ms/step - loss: 0.0050 - val_loss: 0.0087\n",
      "0.9379999999999998\n",
      "Total score: 0.9379999999999998\n",
      "current_patience:  1\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  1.5625e-05\n",
      "11200/11200 [==============================] - 66s 6ms/step - loss: 0.0050 - val_loss: 0.0088\n",
      "0.9395\n",
      "Total score: 0.9395\n",
      "current_patience:  2\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  1.5625e-05\n",
      "11200/11200 [==============================] - 66s 6ms/step - loss: 0.0050 - val_loss: 0.0087\n",
      "0.9352499999999999\n",
      "Total score: 0.9352499999999999\n",
      "current_patience:  3\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  7.8125e-06\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0050 - val_loss: 0.0087\n",
      "0.9384999999999999\n",
      "Total score: 0.9384999999999999\n",
      "current_patience:  4\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  7.8125e-06\n",
      "11200/11200 [==============================] - 66s 6ms/step - loss: 0.0050 - val_loss: 0.0087\n",
      "0.9369999999999998\n",
      "Total score: 0.9369999999999998\n",
      "current_patience:  5\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  7.8125e-06\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0050 - val_loss: 0.0087\n",
      "0.9369999999999998\n",
      "Total score: 0.9369999999999998\n",
      "current_patience:  6\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  3.90625e-06\n",
      "11200/11200 [==============================] - 67s 6ms/step - loss: 0.0050 - val_loss: 0.0087\n",
      "0.9369999999999998\n",
      "Total score: 0.9369999999999998\n",
      "current_patience:  7\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  3.90625e-06\n",
      "11200/11200 [==============================] - 66s 6ms/step - loss: 0.0050 - val_loss: 0.0087\n",
      "0.9337499999999999\n",
      "Total score: 0.9337499999999999\n",
      "current_patience:  8\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  3.90625e-06\n",
      "11200/11200 [==============================] - 66s 6ms/step - loss: 0.0050 - val_loss: 0.0088\n",
      "0.939\n",
      "Total score: 0.939\n",
      "current_patience:  9\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  1.953125e-06\n",
      "11200/11200 [==============================] - 66s 6ms/step - loss: 0.0050 - val_loss: 0.0087\n",
      "0.9359999999999999\n",
      "Total score: 0.9359999999999999\n",
      "current_patience:  10\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      "lr:  1.953125e-06\n",
      "11200/11200 [==============================] - 66s 6ms/step - loss: 0.0050 - val_loss: 0.0087\n",
      "0.938\n",
      "Total score: 0.938\n",
      "current_patience:  11\n",
      "0.9172499999999989\n",
      "0.050000: 0.917250\n",
      "0.9322499999999995\n",
      "0.100000: 0.932250\n",
      "0.9349999999999996\n",
      "0.150000: 0.935000\n",
      "0.939\n",
      "0.200000: 0.939000\n",
      "0.941\n",
      "0.250000: 0.941000\n",
      "0.9355\n",
      "0.300000: 0.935500\n",
      "0.9327500000000001\n",
      "0.350000: 0.932750\n",
      "0.92675\n",
      "0.400000: 0.926750\n",
      "0.9187500000000002\n",
      "0.450000: 0.918750\n",
      "0.9120000000000001\n",
      "0.500000: 0.912000\n",
      "0.9042500000000001\n",
      "0.550000: 0.904250\n",
      "0.8940000000000002\n",
      "0.600000: 0.894000\n",
      "0.8825000000000003\n",
      "0.650000: 0.882500\n",
      "0.8615000000000005\n",
      "0.700000: 0.861500\n",
      "0.8377500000000007\n",
      "0.750000: 0.837750\n",
      "0.779250000000001\n",
      "0.800000: 0.779250\n",
      "0.6565000000000012\n",
      "0.850000: 0.656500\n",
      "0.42425000000000046\n",
      "0.900000: 0.424250\n",
      "0.07725000000000008\n",
      "0.950000: 0.077250\n",
      "kernel_size:  11\n",
      "drop_rate:  0.2\n",
      "filter_num:  16\n",
      "use_lstm:  True\n",
      "varyLR:  False\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "data (InputLayer)               (None, None, 2)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv1D)           (None, None, 16)     368         data[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, None, 16)     64          block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)            (None, None, 16)     0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv1D)           (None, None, 16)     2832        dropout_39[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, None, 16)     64          block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling1D)            (None, None, 16)     0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv1D)           (None, None, 16)     2832        pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, None, 16)     64          block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)            (None, None, 16)     0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv1D)           (None, None, 16)     2832        dropout_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, None, 16)     64          block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "pool2 (MaxPooling1D)            (None, None, 16)     0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv1D)           (None, None, 32)     5664        pool2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, None, 32)     128         block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)            (None, None, 32)     0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv1D)           (None, None, 32)     11296       dropout_41[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, None, 32)     128         block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "pool3 (MaxPooling1D)            (None, None, 32)     0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv1D)           (None, None, 32)     11296       pool3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, None, 32)     128         block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_42 (Dropout)            (None, None, 32)     0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv1D)           (None, None, 32)     11296       dropout_42[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, None, 32)     128         block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "pool4 (MaxPooling1D)            (None, None, 32)     0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv1D)           (None, None, 64)     22592       pool4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, None, 64)     256         block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_43 (Dropout)            (None, None, 64)     0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv1D)           (None, None, 64)     45120       dropout_43[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, None, 64)     256         block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "pool5 (MaxPooling1D)            (None, None, 64)     0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block6_conv1 (Conv1D)           (None, None, 64)     45120       pool5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, None, 64)     256         block6_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_44 (Dropout)            (None, None, 64)     0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block6_conv2 (Conv1D)           (None, None, 64)     45120       dropout_44[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, None, 64)     256         block6_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "pool6 (MaxPooling1D)            (None, None, 64)     0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block7_conv1 (Conv1D)           (None, None, 128)    90240       pool6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, None, 128)    512         block7_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_45 (Dropout)            (None, None, 128)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block7_conv2 (Conv1D)           (None, None, 128)    180352      dropout_45[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, None, 128)    512         block7_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "pool7 (MaxPooling1D)            (None, None, 128)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block8_conv1 (Conv1D)           (None, None, 128)    180352      pool7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, None, 128)    512         block8_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_46 (Dropout)            (None, None, 128)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block8_conv2 (Conv1D)           (None, None, 128)    180352      dropout_46[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, None, 128)    512         block8_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "pool8 (MaxPooling1D)            (None, None, 128)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block9_conv1 (Conv1D)           (None, None, 256)    360704      pool8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, None, 256)    1024        block9_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_47 (Dropout)            (None, None, 256)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block9_conv2 (Conv1D)           (None, None, 256)    721152      dropout_47[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, None, 256)    1024        block9_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "pool9 (MaxPooling1D)            (None, None, 256)    0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block10_conv1 (Conv1D)          (None, None, 256)    721152      pool9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, None, 256)    1024        block10_conv1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_48 (Dropout)            (None, None, 256)    0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block10_conv2 (Conv1D)          (None, None, 256)    721152      dropout_48[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, None, 256)    1024        block10_conv2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, None, 256)    394240      batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_19 (UpSampling1D) (None, None, 256)    0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "up9 (Conv1D)                    (None, None, 256)    65792       up_sampling1d_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, None, 512)    0           up9[0][0]                        \n",
      "                                                                 batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "deconv9_conv1 (Conv1D)          (None, None, 128)    721024      concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, None, 128)    512         deconv9_conv1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_49 (Dropout)            (None, None, 128)    0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "deconv9_conv2 (Conv1D)          (None, None, 128)    180352      dropout_49[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, None, 128)    512         deconv9_conv2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_20 (UpSampling1D) (None, None, 128)    0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up8 (Conv1D)                    (None, None, 128)    16512       up_sampling1d_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, None, 256)    0           up8[0][0]                        \n",
      "                                                                 batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "deconv8_conv1 (Conv1D)          (None, None, 128)    360576      concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, None, 128)    512         deconv8_conv1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_50 (Dropout)            (None, None, 128)    0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "deconv8_conv2 (Conv1D)          (None, None, 128)    180352      dropout_50[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, None, 128)    512         deconv8_conv2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_21 (UpSampling1D) (None, None, 128)    0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "up7 (Conv1D)                    (None, None, 128)    16512       up_sampling1d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, None, 256)    0           up7[0][0]                        \n",
      "                                                                 batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "deconv7_conv1 (Conv1D)          (None, None, 128)    360576      concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, None, 128)    512         deconv7_conv1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_51 (Dropout)            (None, None, 128)    0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "deconv7_conv2 (Conv1D)          (None, None, 128)    180352      dropout_51[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, None, 128)    512         deconv7_conv2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_22 (UpSampling1D) (None, None, 128)    0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "up6 (Conv1D)                    (None, None, 64)     8256        up_sampling1d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, None, 128)    0           up6[0][0]                        \n",
      "                                                                 batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "deconv6_conv1 (Conv1D)          (None, None, 16)     22544       concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, None, 16)     64          deconv6_conv1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_52 (Dropout)            (None, None, 16)     0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "deconv6_conv2 (Conv1D)          (None, None, 16)     2832        dropout_52[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, None, 16)     64          deconv6_conv2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_23 (UpSampling1D) (None, None, 16)     0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "up5 (Conv1D)                    (None, None, 64)     1088        up_sampling1d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, None, 128)    0           up5[0][0]                        \n",
      "                                                                 batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "deconv5_conv1 (Conv1D)          (None, None, 16)     22544       concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, None, 16)     64          deconv5_conv1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_53 (Dropout)            (None, None, 16)     0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "deconv5_conv2 (Conv1D)          (None, None, 16)     2832        dropout_53[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, None, 16)     64          deconv5_conv2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_24 (UpSampling1D) (None, None, 16)     0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "up4 (Conv1D)                    (None, None, 32)     544         up_sampling1d_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, None, 64)     0           up4[0][0]                        \n",
      "                                                                 batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "deconv4_conv1 (Conv1D)          (None, None, 16)     11280       concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, None, 16)     64          deconv4_conv1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_54 (Dropout)            (None, None, 16)     0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "deconv4_conv2 (Conv1D)          (None, None, 16)     2832        dropout_54[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, None, 16)     64          deconv4_conv2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_25 (UpSampling1D) (None, None, 16)     0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "up3 (Conv1D)                    (None, None, 32)     544         up_sampling1d_25[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, None, 64)     0           up3[0][0]                        \n",
      "                                                                 batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "deconv3_conv1 (Conv1D)          (None, None, 16)     11280       concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, None, 16)     64          deconv3_conv1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_55 (Dropout)            (None, None, 16)     0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "deconv3_conv2 (Conv1D)          (None, None, 16)     2832        dropout_55[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, None, 16)     64          deconv3_conv2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_26 (UpSampling1D) (None, None, 16)     0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "up2 (Conv1D)                    (None, None, 16)     272         up_sampling1d_26[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, None, 32)     0           up2[0][0]                        \n",
      "                                                                 batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "deconv2_conv1 (Conv1D)          (None, None, 16)     5648        concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, None, 16)     64          deconv2_conv1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_56 (Dropout)            (None, None, 16)     0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "deconv2_conv2 (Conv1D)          (None, None, 16)     2832        dropout_56[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, None, 16)     64          deconv2_conv2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_27 (UpSampling1D) (None, None, 16)     0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "up1 (Conv1D)                    (None, None, 16)     272         up_sampling1d_27[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, None, 32)     0           up1[0][0]                        \n",
      "                                                                 batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "deconv1_conv1 (Conv1D)          (None, None, 16)     5648        concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, None, 16)     64          deconv1_conv1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_57 (Dropout)            (None, None, 16)     0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "deconv1_conv2 (Conv1D)          (None, None, 16)     2832        dropout_57[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, None, 16)     64          deconv1_conv2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv10 (Conv1D)                 (None, None, 1)      17          batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Conv1D)            (None, None, 1)      2           conv10[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 5,956,819\n",
      "Trainable params: 5,950,931\n",
      "Non-trainable params: 5,888\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape (2000, 5000, 1)\n",
      "Y.shape (2000, 5000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Roaming\\Python\\Python35\\site-packages\\sklearn\\preprocessing\\data.py:180: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\dell\\AppData\\Roaming\\Python\\Python35\\site-packages\\sklearn\\preprocessing\\data.py:197: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 5000, 2)\n",
      "(2000, 5000, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validating...\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/1\n",
      " 2272/11200 [=====>........................] - ETA: 2:30 - loss: 0.2349"
     ]
    }
   ],
   "source": [
    "from keras.utils import plot_model, np_utils\n",
    "from keras.callbacks import CSVLogger, EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, scale\n",
    "import unet_lstm_mse_simple_9pool\n",
    "import scipy.io as sio\n",
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "from operator import itemgetter \n",
    "from dataset import loaddata2, loaddata2_wavelet\n",
    "from score_model import score_model_new\n",
    "from sklearn.model_selection import KFold\n",
    "from Score_earlystop import Score_earlystop_varyLR, Score_earlystop_new\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing import sequence\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (18, 6)\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    for filter_num, kernel_size, drop_rate, use_lstm, varyLR in [(16, 11, 0.2, True, True),(32, 7, 0.2, False, True),(16, 11, 0.2, True, False),(32, 7, 0.2, False, False)]:\n",
    "        print('kernel_size: ', kernel_size)\n",
    "        print('drop_rate: ', drop_rate)\n",
    "        print('filter_num: ', filter_num)\n",
    "        print('use_lstm: ', use_lstm)\n",
    "        print('varyLR: ', varyLR)\n",
    "        # build model\n",
    "        #eg_length = 4992\n",
    "        model = unet_lstm_mse_simple_9pool.unet((None, 4), 1, 0.001, kernel_size=kernel_size, filter_num=filter_num, \n",
    "                                          res=0, drop_rate=drop_rate, maxpool=True, weights=None, use_lstm=use_lstm)\n",
    "        model.summary()\n",
    "        plot_model(model, show_shapes=True, to_file='model_unet.png')\n",
    "        model_json = model.to_json()\n",
    "        with open('model_varyLR'+str(varyLR)+'_diffnormal_rev_unet_uselstm'+str(use_lstm)+'_16filters_9pools_kernel'+str(kernel_size)+'_drop'+str(drop_rate)+'.json', \"w\") as json_file:\n",
    "            json_file.write(model_json)\n",
    "\n",
    "        init_weights = model.get_weights()\n",
    "\n",
    "        input_dir = 'Training data3/train/data'\n",
    "        ref_dir = 'Training data3/train/ref'\n",
    "        X,Y,QRS = loaddata2(input_dir, ref_dir, sigmoid=10, do_normalize=False)\n",
    "        X_rev = X * -1\n",
    "        X_diff = np.diff(X, axis=1)\n",
    "        X_diff = sequence.pad_sequences(X_diff, maxlen=X.shape[1], dtype='float32', padding='post')\n",
    "        \n",
    "        X_diff = scale(X_diff.squeeze(), axis=1)\n",
    "        X_diff = np.expand_dims(X_diff, axis=-1)\n",
    "        X_diff_rev = X_diff * -1\n",
    "        X = np.concatenate((X, X_rev, X_diff, X_diff_rev), axis=-1)\n",
    "        print(X.shape)\n",
    "        print(Y.shape)\n",
    "\n",
    "        fig, axes = plt.subplots(nrows=2, sharex=True)\n",
    "        axes[0].plot(X[0])\n",
    "        axes[1].plot(Y[0])\n",
    "        plt.show()\n",
    "        \n",
    "        # K-Folds\n",
    "        flods = 5\n",
    "        # fold for pre-test. range: 0:flods-1\n",
    "        selected_flod = 1\n",
    "\n",
    "        #--------------------------------------------------------------------------\n",
    "        # K-fold cross validation test harness\n",
    "        #--------------------------------------------------------------------------\n",
    "        if __name__ == '__main__':\n",
    "            print('Cross validating...')\n",
    "            kfold = KFold(n_splits=flods, shuffle = True, random_state = 7)\n",
    "            cvscores_dnn = []\n",
    "\n",
    "            fold_id = -1\n",
    "            for train, test in kfold.split(X):\n",
    "\n",
    "                # only run the selected fold\n",
    "                fold_id+=1\n",
    "        #         if fold_id != selected_flod:\n",
    "        #             continue\n",
    "                x_train = X[train]\n",
    "                y_train = Y[train]\n",
    "                x_test =  X[test]\n",
    "                y_test =  Y[test]\n",
    "                #segment\n",
    "                seg_length = 2000\n",
    "                x_train_seg = [] \n",
    "                y_train_seg = []\n",
    "                x_test_seg = []\n",
    "                y_test_seg = []\n",
    "                for i in range(len(x_train)):\n",
    "                    for j in range(0,3500,500):\n",
    "                        x_train_seg.append(x_train[i,j:j+seg_length])\n",
    "                        y_train_seg.append(y_train[i,j:j+seg_length])\n",
    "\n",
    "                for i in range(len(x_test)):\n",
    "                    for j in range(0,3500,500):\n",
    "                        x_test_seg.append(x_test[i,j:j+seg_length])\n",
    "                        y_test_seg.append(y_test[i,j:j+seg_length])\n",
    "\n",
    "                x_train_seg = np.array(x_train_seg, dtype=np.float32)\n",
    "                y_train_seg = np.array(y_train_seg, dtype=np.float32)\n",
    "                x_test_seg = np.array(x_test_seg, dtype=np.float32)\n",
    "                y_test_seg = np.array(y_test_seg, dtype=np.float32)\n",
    "\n",
    "                x_train_seg = sequence.pad_sequences(x_train_seg, maxlen=2048, dtype='float32', padding='post')\n",
    "                y_train_seg = sequence.pad_sequences(y_train_seg, maxlen=2048, dtype='float32', padding='post')\n",
    "                x_test_seg = sequence.pad_sequences(x_test_seg, maxlen=2048, dtype='float32', padding='post')\n",
    "                y_test_seg = sequence.pad_sequences(y_test_seg, maxlen=2048, dtype='float32', padding='post')\n",
    "\n",
    "                # train\n",
    "                best_model_file = 'best_varyLR'+str(varyLR)+'_diffnormal_rev_unet_uselstm'+str(use_lstm)+'_normal_'+str(filter_num)+'filters_9pools_kernel'+str(kernel_size)+'_drop'+str(drop_rate)+'_'+str(fold_id)+'.model'\n",
    "                early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    "                model_checkpoint = ModelCheckpoint(\n",
    "                    best_model_file,\n",
    "                    monitor = 'val_loss',\n",
    "                    save_best_only = True,\n",
    "                    verbose=1)\n",
    "\n",
    "                model.set_weights(init_weights)\n",
    "\n",
    "                QRS_test = itemgetter(*test)(QRS)\n",
    "                if varyLR:\n",
    "                    Score_earlystop_varyLR(model, x_train_seg, y_train_seg,\n",
    "                                          x_test_seg, y_test_seg, x_test, QRS_test, 32,\n",
    "                                          500, None, 10, best_model_file,\n",
    "                                          lr_patience=3)\n",
    "                else:\n",
    "                    Score_earlystop_new(model, x_train_seg, y_train_seg,\n",
    "                                          x_test_seg, y_test_seg, x_test, QRS_test, 32,\n",
    "                                          500, None, 10, best_model_file)\n",
    "                        \n",
    "\n",
    "\n",
    "                model.load_weights(best_model_file)\n",
    "\n",
    "                for i in range(1,20):\n",
    "                    mean_score = score_model_new(model, x_test, QRS_test, i/20.0)\n",
    "                    print('%f: %f' % (i/20.0, mean_score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test CPSC2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape (2000, 5000, 1)\n",
      "Y.shape (2000, 5000, 1)\n",
      "Cross validating...\n",
      "#########################\n",
      "0.8820000000000001\n",
      "0.100000: 0.882000\n",
      "0.8815000000000002\n",
      "0.200000: 0.881500\n",
      "0.8802500000000002\n",
      "0.300000: 0.880250\n",
      "0.8717500000000002\n",
      "0.400000: 0.871750\n",
      "0.8672500000000004\n",
      "0.500000: 0.867250\n",
      "0.8595000000000003\n",
      "0.600000: 0.859500\n",
      "0.8335000000000005\n",
      "0.700000: 0.833500\n",
      "0.7247500000000006\n",
      "0.800000: 0.724750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Roaming\\Python\\Python35\\site-packages\\numpy\\core\\fromnumeric.py:2909: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\dell\\AppData\\Roaming\\Python\\Python35\\site-packages\\numpy\\core\\_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41624999999999984\n",
      "0.900000: 0.416250\n",
      "#########################\n",
      "0.8954999999999999\n",
      "0.100000: 0.895500\n",
      "0.89\n",
      "0.200000: 0.890000\n",
      "0.8750000000000001\n",
      "0.300000: 0.875000\n",
      "0.8570000000000002\n",
      "0.400000: 0.857000\n",
      "0.8215000000000003\n",
      "0.500000: 0.821500\n",
      "0.7870000000000006\n",
      "0.600000: 0.787000\n",
      "0.6335000000000007\n",
      "0.700000: 0.633500\n",
      "0.26024999999999976\n",
      "0.800000: 0.260250\n",
      "0.07600000000000003\n",
      "0.900000: 0.076000\n",
      "#########################\n",
      "0.8732499999999997\n",
      "0.100000: 0.873250\n",
      "0.8815\n",
      "0.200000: 0.881500\n",
      "0.87725\n",
      "0.300000: 0.877250\n",
      "0.8665\n",
      "0.400000: 0.866500\n",
      "0.8442500000000002\n",
      "0.500000: 0.844250\n",
      "0.7727500000000002\n",
      "0.600000: 0.772750\n",
      "0.6177500000000005\n",
      "0.700000: 0.617750\n",
      "0.24999999999999986\n",
      "0.800000: 0.250000\n",
      "0.1399999999999999\n",
      "0.900000: 0.140000\n",
      "#########################\n",
      "0.8544999999999997\n",
      "0.100000: 0.854500\n",
      "0.8447499999999999\n",
      "0.200000: 0.844750\n",
      "0.8444999999999999\n",
      "0.300000: 0.844500\n",
      "0.8375000000000001\n",
      "0.400000: 0.837500\n",
      "0.8347500000000001\n",
      "0.500000: 0.834750\n",
      "0.8190000000000002\n",
      "0.600000: 0.819000\n",
      "0.7862500000000004\n",
      "0.700000: 0.786250\n",
      "0.7117500000000005\n",
      "0.800000: 0.711750\n",
      "0.5077500000000004\n",
      "0.900000: 0.507750\n",
      "#########################\n",
      "0.8982499999999998\n",
      "0.100000: 0.898250\n",
      "0.8897499999999999\n",
      "0.200000: 0.889750\n",
      "0.8812499999999999\n",
      "0.300000: 0.881250\n",
      "0.88\n",
      "0.400000: 0.880000\n",
      "0.8745\n",
      "0.500000: 0.874500\n",
      "0.8597500000000002\n",
      "0.600000: 0.859750\n",
      "0.8160000000000004\n",
      "0.700000: 0.816000\n",
      "0.7415000000000007\n",
      "0.800000: 0.741500\n",
      "0.49000000000000027\n",
      "0.900000: 0.490000\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model,model_from_json, Model\n",
    "from score_model import score_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dataset import loaddata2\n",
    "from operator import itemgetter \n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "input_dir = 'Training data3/train/data'\n",
    "ref_dir = 'Training data3/train/ref'\n",
    "X,Y,QRS = loaddata2(input_dir, ref_dir)\n",
    "X_rev = X * -1\n",
    "X = np.concatenate((X,X_rev), axis=-1)\n",
    "#x_train, x_test, y_train, y_test, QRS_train, QRS_test = train_test_split(X, Y, QRS, test_size=0.20, random_state=7)\n",
    "# K-Folds\n",
    "flods = 5\n",
    "# fold for pre-test. range: 0:flods-1\n",
    "selected_flod = 1\n",
    "\n",
    "#--------------------------------------------------------------------------\n",
    "# K-fold cross validation test harness\n",
    "#--------------------------------------------------------------------------\n",
    "if __name__ == '__main__':\n",
    "    print('Cross validating...')\n",
    "    kfold = KFold(n_splits=flods, shuffle = True, random_state = 7)\n",
    "    cvscores_dnn = []\n",
    "\n",
    "    fold_id = -1\n",
    "    for train, test in kfold.split(X):\n",
    "\n",
    "        # only run the selected fold\n",
    "        fold_id+=1\n",
    "#         if fold_id != selected_flod:\n",
    "#             continue\n",
    "        x_train = X[train]\n",
    "        y_train = Y[train]\n",
    "        x_test =  X[test]\n",
    "        y_test =  Y[test]\n",
    "        QRS_test = itemgetter(*test)(QRS)\n",
    "        # load model\n",
    "        model_structure_file = 'model_unet_lstm2_unique_shuffle_2channel_newdata3_segment_MITDB_pretrain_10s_10early_4s_Score.json'\n",
    "        model_weights_file = 'best_unet_lstm2_unique_shuffle_2channel_2000_newdata3_model_segment_MITDB_pretrain_10s_10early_4s_Score_'+str(fold_id)+'.model'\n",
    "\n",
    "        json_file = open(model_structure_file, 'r')  \n",
    "        loaded_model_json = json_file.read()  \n",
    "        json_file.close()  \n",
    "        model = model_from_json(loaded_model_json)\n",
    "        model.load_weights(model_weights_file)\n",
    "        print('#########################')\n",
    "        for i in range(1,10):\n",
    "            mean_score = score_model(model, x_test, QRS_test, i/10.0)\n",
    "            print('%f: %f' % (i/10.0, mean_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
